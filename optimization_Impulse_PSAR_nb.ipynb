{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import datetime as dt\n",
    "import mplfinance \n",
    "from renkodf import Renko\n",
    "from scipy.signal import lfilter\n",
    "import fx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971.01.04</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971.01.05</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971.01.06</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1971.01.07</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1971.01.08</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1971.01.11</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1971.01.12</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1971.01.13</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1971.01.14</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1971.01.15</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   time    open    high     low   close  volume\n",
       "0  1971.01.04  00:00  0.5369  0.5369  0.5369  0.5369       1\n",
       "1  1971.01.05  00:00  0.5366  0.5366  0.5366  0.5366       1\n",
       "2  1971.01.06  00:00  0.5365  0.5365  0.5365  0.5365       1\n",
       "3  1971.01.07  00:00  0.5368  0.5368  0.5368  0.5368       1\n",
       "4  1971.01.08  00:00  0.5371  0.5371  0.5371  0.5371       1\n",
       "5  1971.01.11  00:00  0.5371  0.5371  0.5371  0.5371       1\n",
       "6  1971.01.12  00:00  0.5371  0.5371  0.5371  0.5371       1\n",
       "7  1971.01.13  00:00  0.5373  0.5373  0.5373  0.5373       1\n",
       "8  1971.01.14  00:00  0.5372  0.5372  0.5372  0.5372       1\n",
       "9  1971.01.15  00:00  0.5376  0.5376  0.5376  0.5376       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the actual data from csv file\n",
    "filename = \"C:/Users/WilliamFetzner/Documents/Trading/EURUSD1.csv\"\n",
    "df = pd.read_csv(filename, header=None, names=['date', 'time', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime\n",
    "df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'], format='%Y.%m.%d %H:%M')\n",
    "# filter the data to just 2023\n",
    "\n",
    "df_2022 = fx.prep_data(df, 2022)\n",
    "df_2023 = fx.prep_data(df, 2023)\n",
    "df_2024 = fx.prep_data(df, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renko variable\n",
    "initial_brick_size = 0.000325\n",
    "# create a list of possible brick sizes a max at 0.001 and min at 0.00001 and each step is 0.00001\n",
    "brick_size_list = np.arange(0.00001, 0.00101, 0.00001)\n",
    "\n",
    "# psar variables\n",
    "start = 0.02\n",
    "increment = 0.02\n",
    "increment_list = np.arange(0.001, 0.2001, 0.0001)\n",
    "maximum = 0.2\n",
    "max_list = np.arange(0.01, 0.501, 0.001)\n",
    "\n",
    "# impulse variables\n",
    "lengthMA = 34\n",
    "ma_list = np.arange(10, 100, 1)\n",
    "lengthSignal = 9\n",
    "signal_list = np.arange(1, 51, 1)\n",
    "\n",
    "# Lot Size\n",
    "lot_size = 10\n",
    "lot_sizes_list = np.arange(1, 21, 1)\n",
    "per_lot = 100000\n",
    "\n",
    "# Commissions\n",
    "nova_commission = lot_size * -3\n",
    "msolutions_commission = lot_size * -5\n",
    "\n",
    "# starting balance\n",
    "balance = 200000\n",
    "\n",
    "# base currency rate\n",
    "base_currency_rate = 0.045 # EUR\n",
    "quote_currency_rate = 0.055 # USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renko_ready(df, brick_size):\n",
    "    # create a renko chart from the df dataframe\n",
    "    r_full = Renko(df, brick_size=brick_size)\n",
    "    # create a new dataframe from the renko features\n",
    "    renko_data = r_full.renko_df()\n",
    "    # rename 'volume' to 'nbars'\n",
    "    renko_data = renko_data.rename(columns={'volume': 'nbars'})\n",
    "    return renko_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_cols(df, inc, max, ma, signal, stop_loss):\n",
    "    # adding psar to the dataframe\n",
    "    r_w_psar = fx.psar_from_data(df, inc, max)\n",
    "    # adding impulse to the dataframe\n",
    "    r_w_impulse = fx.calc_impulse_macd(r_w_psar, ma, signal)\n",
    "    # add the brick color to the dataframe\n",
    "    r_w_impulse['brick_color'] = np.where(r_w_impulse['open'] > r_w_impulse['close'], 'red', 'green')\n",
    "    # add the day of the week to the dataframe\n",
    "    r_w_impulse['day_of_week'] = r_w_impulse.index.day_name()\n",
    "    # place a 1 in day_of_week_transition, if it is the last bar on Friday and the next bar is Sunday\n",
    "    r_w_impulse['day_of_week_transition'] = np.where((r_w_impulse['day_of_week'] == 'Friday') & \n",
    "                                                     ((r_w_impulse['day_of_week'].shift(-1) == 'Sunday') | (r_w_impulse['day_of_week'].shift(-1) == 'Monday')), 1, 0)\n",
    "\n",
    "    #### entry conditions ####\n",
    "    # add a column that will be the entry signal for the strategy to be when both impulse_signal and psar_signal are both 'buy' or 'sell'\n",
    "    r_w_impulse['entry_signal'] = np.where((r_w_impulse['psar_signal'] == 'buy') & (r_w_impulse['impulse_signal'] == 'buy') \n",
    "                                            & (r_w_impulse['brick_color'] == 'green') & (r_w_impulse['day_of_week_transition'] != 1), 'long', \n",
    "                                            np.where((r_w_impulse['psar_signal'] == 'sell') & (r_w_impulse['impulse_signal'] == 'sell') & \n",
    "                                                    (r_w_impulse['brick_color'] == 'red') & (r_w_impulse['day_of_week_transition'] != 1), 'short', 'none'))\n",
    "\n",
    "    # if there was a change from 'none' to 'buy' or 'sell' then that is an entry signal and replace the 'buy' or 'sell' with 'entry + long' or 'entry + sell'\n",
    "    r_w_impulse['entry_signal'] = np.where((r_w_impulse['entry_signal'] != 'none') & (r_w_impulse['entry_signal'].shift(1) == 'none'),\n",
    "                                                'entry + ' + r_w_impulse['entry_signal'], r_w_impulse['entry_signal'])\n",
    "\n",
    "    #### Exit conditions ####\n",
    "    # add a stop loss column that will be the entry price +/- the brick size for when the entry signal is 'entry + long' or 'entry + sell'\n",
    "    r_w_impulse['stop_loss'] = np.where(r_w_impulse['entry_signal'] == 'entry + long', r_w_impulse['open'] - stop_loss,\n",
    "                                            np.where(r_w_impulse['entry_signal'] == 'entry + short', r_w_impulse['open'] + stop_loss, np.nan))\n",
    "    \n",
    "    # if the 'entry_signal' colummn goes from 'entry + short' or 'short' to 'none' then 'none' should be replaced with 'exit' in the entry_signal column\n",
    "    r_w_impulse['entry_signal'] = np.where((r_w_impulse['entry_signal'].shift(1) == 'entry + short') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                np.where((r_w_impulse['entry_signal'].shift(1) == 'short') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                        np.where((r_w_impulse['entry_signal'].shift(1) == 'entry + long') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                                np.where((r_w_impulse['entry_signal'].shift(1) == 'long') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                                        r_w_impulse['entry_signal']))))\n",
    "    # position_count will be a cumulative count used to filter the data to the timeframe between the entry \n",
    "    # and exit signals so anytime there is an \"entry + long\" or \"entry + short\" the count should increase by 1\n",
    "    r_w_impulse['position_count'] = np.where(r_w_impulse['entry_signal'] == 'entry + long', 1, np.where(r_w_impulse['entry_signal'] == 'entry + short', 1, 0))\n",
    "    r_w_impulse['cum_position_count'] = r_w_impulse['position_count'].cumsum()\n",
    "    # when 'entry_signal' is 'none' then the 'cum_position_count' should be null\n",
    "    r_w_impulse['cum_position_count'] = np.where(r_w_impulse['entry_signal'] == 'none', np.nan, r_w_impulse['cum_position_count'])\n",
    "    # group by cum_position_count and forward fill the value in the first index of the 'stop_loss' column\n",
    "    r_w_impulse['stop_loss'] = r_w_impulse.groupby('cum_position_count')['stop_loss'].ffill()\n",
    "    # determine whether the exit should be sooner because the stop_loss was hit before the exit signal (look at the high/low of the brick)\n",
    "    r_w_impulse['exit_stop_loss'] = np.where((r_w_impulse['entry_signal'] == 'long') & (r_w_impulse['stop_loss'] > r_w_impulse['low']), 1,\n",
    "                                            np.where((r_w_impulse['entry_signal'] == 'short') & (r_w_impulse['stop_loss'] < r_w_impulse['high']), 1, 0))\n",
    "    \n",
    "    return r_w_impulse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_profit_loss(df, lots):\n",
    "    profit_df = pd.DataFrame() #columns=['cum_position_count', 'direction', 'entry_price', 'exit_price', 'first_TP_hit', 'profit']\n",
    "# calculate the profit for each position by first grouping by each position and finding the entry price\n",
    "    profit_df['entry_price'] = df.groupby('cum_position_count')['close'].first()\n",
    "    # separate out the datetime column\n",
    "    df['datetime'] = df.index\n",
    "    # get the entry and exit times\n",
    "    profit_df['entry_time'] = df.groupby('cum_position_count')['datetime'].first()\n",
    "    profit_df['exit_time'] = df.groupby('cum_position_count')['datetime'].last()\n",
    "    # # determine the exit price\n",
    "    profit_df['exit_price'] = df.groupby('cum_position_count')['close'].last()\n",
    "    # # what was the direction, long or short?\n",
    "    profit_df['direction'] = df.groupby('cum_position_count')['entry_signal'].first()\n",
    "    profit_df['direction'] = profit_df['direction'].str.split('+').str[1]\n",
    "    profit_df['profit'] = np.where((profit_df['direction'].str.strip() == 'long'),\n",
    "                                            (profit_df['exit_price'] - profit_df['entry_price'])*per_lot*(lots), \n",
    "                                            np.where((profit_df['direction'].str.strip() == 'short'),\n",
    "                                                    (profit_df['entry_price'] - profit_df['exit_price'])*per_lot*(lots), np.nan))\n",
    "    profit_df = fx.add_swap_rates(profit_df, base_currency_rate, quote_currency_rate, lots=lots)\n",
    "    profit_df['nova_profit'] = profit_df['profit'] + nova_commission + profit_df['swap_rate']\n",
    "    profit_df['msolutions_profit'] = profit_df['profit'] + msolutions_commission + profit_df['swap_rate']\n",
    "    # use the entry time and resample to each day and find the sum of the profit\n",
    "    profit_df['entry_time'] = pd.to_datetime(profit_df['entry_time'])\n",
    "    profit_df_new_index = profit_df.set_index('entry_time')\n",
    "    # find the sum of the nova and msolutions profit for each day\n",
    "    profit_df_daily = profit_df_new_index.resample('D').agg({'nova_profit': 'sum'})\n",
    "    # find the number of times that profit_df_daily is below zero\n",
    "    profit_df_daily['nova_negative'] = np.where(profit_df_daily['nova_profit'] < 0, 1, 0)\n",
    "    # find the sum of nova_negative and msolutions_negative\n",
    "    nova_negative_sum = profit_df_daily['nova_negative'].sum()\n",
    "    # find the sum of nova_profit\n",
    "    nova_profit_sum = profit_df['nova_profit'].sum()\n",
    "\n",
    "    return nova_profit_sum, nova_negative_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20509.999999937732, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def making_calculations(df, brick_size, inc, max, ma, signal, stop_loss, lot_size):\n",
    "    renko_data = renko_ready(df, brick_size)\n",
    "    # add the columns necessary for the strategy\n",
    "    renko_data_cols_added = adding_cols(renko_data, inc, max, ma, signal, stop_loss)\n",
    "    # determine the profit/loss for the strategy\n",
    "    total_profit, days_in_drawdown = calc_profit_loss(renko_data_cols_added, lot_size)\n",
    "\n",
    "    return total_profit, days_in_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 data:  (1136669.999999, 53)\n",
      "2023 data:  (447824.99999925366, 82)\n",
      "2024 data:  (20509.999999937732, 15)\n"
     ]
    }
   ],
   "source": [
    "# results for standard values\n",
    "print('2022 data: ', making_calculations(df_2022, initial_brick_size, start, maximum, lengthMA, lengthSignal, initial_brick_size*2, lot_size))\n",
    "print('2023 data: ', making_calculations(df_2023, initial_brick_size, start, maximum, lengthMA, lengthSignal, initial_brick_size*2, lot_size))\n",
    "print('2024 data: ', making_calculations(df_2024, initial_brick_size, start, maximum, lengthMA, lengthSignal, initial_brick_size*2, lot_size))\n",
    "# 2022 data:  ($1,136,669.99, 53)\n",
    "# 2023 data:  ($447,824.99, 82)\n",
    "# 2024 data:  ($20,509.99, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an optimization function that goes through all the possible combinations of the variables with tqdm on each loop to show progress\n",
    "def optimization_fx(df, brick_size_list, increment_list, max_list, ma_list, signal_list, lot_sizes_list):\n",
    "    # create a list to store the results\n",
    "    results = []\n",
    "    # loop through each possible combination of the variables\n",
    "    for brick_size in tqdm(brick_size_list):\n",
    "        for inc in tqdm(increment_list):\n",
    "            for max in tqdm(max_list):\n",
    "                for ma in tqdm(ma_list):\n",
    "                    for signal in tqdm(signal_list):\n",
    "                        for lot_size in tqdm(lot_sizes_list):\n",
    "                            # calculate the profit/loss for each combination of variables\n",
    "                            total_profit, days_in_drawdown = making_calculations(df, brick_size, inc, max, ma, signal, brick_size*2, lot_size)\n",
    "                            # append the results to the results list\n",
    "                            results.append([brick_size, inc, max, ma, signal, lot_size, total_profit, days_in_drawdown])\n",
    "    # create a dataframe from the results list\n",
    "    results_df = pd.DataFrame(results, columns=['brick_size', 'increment', 'maximum', 'ma', 'signal', 'lot_size', 'total_profit', 'days_in_drawdown'])\n",
    "    # normalize total_profit and days_in_drawdown\n",
    "    results_df['norm_total_profit'] = statistics.zscore(results_df['total_profit'])\n",
    "    results_df['norm_days_in_drawdown'] = statistics.zscore(results_df['days_in_drawdown']) * -1\n",
    "    # find the total of the normalized columns\n",
    "    results_df['score'] = results_df['norm_total_profit'] + results_df['norm_days_in_drawdown']\n",
    "\n",
    "    # find the best results\n",
    "    most_profitable = results_df[results_df['total_profit'] == results_df['total_profit'].max()]\n",
    "    least_drawdown = results_df[results_df['days_in_drawdown'] == results_df['days_in_drawdown'].min()]\n",
    "    best_results = results_df[results_df['score'] == results_df['score'].max()]\n",
    "    return results_df, most_profitable, least_drawdown, best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7606b8dc6832478baa3e56f93d9b3b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe86d67d3543ea9f79e89e86aa4978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1991 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414ca9c2d2934ada801b5a1dfcbb05c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ed0e233dea464c9f2de6d64e3bf080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2090de42a1ff4be18ff0a498bace11ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f34a82ce9f4d77aed2782aa9361f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df, most_profitable, least_drawdown, best_results = optimization_fx(df_2022, brick_size_list, increment_list, max_list, ma_list, signal_list, lot_sizes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_profitable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment forex-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment forex-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment stocks-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment stocks-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment crypto-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment crypto-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment mixed-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment mixed-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gymnasium as gym\n",
        "import gym_mtsim\n",
        "sys.path.append(\"C:/Users/WilliamFetzner/Documents/Trading/\")\n",
        "from gym_mtsim_forked.gym_mtsim.data import FOREX_DATA_PATH, FOREX_DATA_PATH_1HR, FOREX_DATA_PATH_15MIN, FOREX_DATA_PATH_5MIN\n",
        "from gym_mtsim import OrderType, Timeframe, MtEnv, MtSimulator\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, STATUS_FAIL\n",
        "from stable_baselines3 import A2C, PPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "import time\n",
        "import torch\n",
        "import pickle\n",
        "import fx_rl\n",
        "from datetime import datetime, timedelta\n",
        "import pytz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latest Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "current_time = pd.to_datetime(now) + timedelta(hours=7)\n",
        "current_time = current_time.replace(tzinfo=pytz.UTC)\n",
        "# date_15min = fx_rl.bars_back(current_time, 'M15')\n",
        "# date_5min = fx_rl.bars_back(current_time, 'M5')\n",
        "date_1hr = fx_rl.bars_back(current_time, 'H1', total_bars=50_000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim = MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=10000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=False,\n",
        ")\n",
        "sim.download_data(\n",
        "    symbols=['EURUSD', 'AUDCHF', 'NZDCHF', 'GBPNZD', 'USDCAD'],\n",
        "    time_range=(\n",
        "        date_1hr,\n",
        "        current_time\n",
        "    ),\n",
        "    timeframe=Timeframe.H1\n",
        ")\n",
        "sim.save_symbols(FOREX_DATA_PATH)\n",
        "# sim.save_symbols(f'symbols_forex_15min_{date_1hr.date()}_{current_time.date()}.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open(f'symbols_forex_5min_2023-01-09_2024-05-08', 'rb') as f:\n",
        "#     symbols_5min = pickle.load(f)\n",
        "# # convert symbols_5min to a pd.dataframe\n",
        "# symbols_5min[1]['EURUSD'].index = pd.to_datetime(symbols_5min[1]['EURUSD'].index)\n",
        "# max_date_5min = symbols_5min[1]['EURUSD'].index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open(f'symbols_forex_15min_2020-05-11_2024-05-08', 'rb') as f:\n",
        "#     symbols_15min = pickle.load(f)\n",
        "# # convert symbols_15min to a pd.dataframe\n",
        "# symbols_15min[1]['EURUSD'].index = pd.to_datetime(symbols_15min[1]['EURUSD'].index)\n",
        "# max_date_15min = symbols_15min[1]['EURUSD'].index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(FOREX_DATA_PATH, 'rb') as f:\n",
        "    symbols_1hr = pickle.load(f)\n",
        "# convert symbols_1hr to a pd.dataframe\n",
        "symbols_1hr[1]['EURUSD'].index = pd.to_datetime(symbols_1hr[1]['EURUSD'].index)\n",
        "max_date_1hr = symbols_1hr[1]['EURUSD'].index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # unpack the pickle file and load the data that is in symbols_forex.pkl\n",
        "# with open(FOREX_DATA_PATH, 'rb') as f:\n",
        "#     symbols = pickle.load(f)\n",
        "# # convert symbols to a pd.dataframe\n",
        "# # symbols[1]['EURUSD']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# slices_5min = fx_rl.slices_finder(symbols_5min[1]['EURUSD'], max_date_5min, testing_needed=True)\n",
        "# slices_15min = fx_rl.slices_finder(symbols_15min[1]['EURUSD'], max_date_15min, testing_needed=True)\n",
        "slices_1hr = fx_rl.slices_finder(symbols_1hr[1]['EURUSD'], max_date_1hr, testing_needed=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class MyMtEnv(gym_mtsim.MtEnv):\n",
        "#     # _get_modified_volume = fx_rl.my_get_modified_volume\n",
        "#     _get_prices = fx_rl.my_get_prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_train_1hr = gym_mtsim.MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=200000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=True,\n",
        "    symbols_filename=FOREX_DATA_PATH_1HR\n",
        ")\n",
        "\n",
        "env_train_1hr = gym_mtsim.MtEnv(\n",
        "    original_simulator=sim_train_1hr,\n",
        "    trading_symbols=['EURUSD'],\n",
        "    window_size = 10,\n",
        "    time_points=slices_1hr[0],\n",
        "    hold_threshold=0.5,\n",
        "    close_threshold=0.5,\n",
        "    fee=lambda symbol: {\n",
        "        # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "        'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "        # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "    }[symbol],\n",
        "    symbol_max_orders=2,\n",
        "    multiprocessing_processes=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim_train_15min = gym_mtsim.MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=200000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=True,\n",
        "#     symbols_filename=FOREX_DATA_PATH_15MIN\n",
        "# )\n",
        "\n",
        "# env_train_15min = gym_mtsim.MtEnv(\n",
        "#     original_simulator=sim_train_15min,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = 10,\n",
        "#     time_points=slices_15min[0],\n",
        "#     hold_threshold=0.5,\n",
        "#     close_threshold=0.5,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim_train_5min = gym_mtsim.MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=200000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=True,\n",
        "#     symbols_filename=FOREX_DATA_PATH_5MIN\n",
        "# )\n",
        "\n",
        "# env_train_5min = gym_mtsim.MtEnv(\n",
        "#     original_simulator=sim_train_5min,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = 10,\n",
        "#     time_points=slices_5min[0],\n",
        "#     hold_threshold=0.5,\n",
        "#     close_threshold=0.5,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_validation_1hr = MtSimulator(\n",
        "    unit='USD',\n",
        "    balance=200000.,\n",
        "    leverage=100.,\n",
        "    stop_out_level=0.2,\n",
        "    hedge=True,\n",
        "    symbols_filename=FOREX_DATA_PATH\n",
        ")\n",
        "\n",
        "env_validation_1hr = gym_mtsim.MtEnv(\n",
        "    original_simulator=sim_validation_1hr,\n",
        "    trading_symbols=['EURUSD'],\n",
        "    window_size = 10,\n",
        "    time_points=slices_1hr[1],\n",
        "    hold_threshold=0.5,\n",
        "    close_threshold=0.5,\n",
        "    fee=lambda symbol: {\n",
        "        # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "        'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "        # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "    }[symbol],\n",
        "    symbol_max_orders=2,\n",
        "    multiprocessing_processes=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim_validation_15min = gym_mtsim.MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=200000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=True,\n",
        "#     symbols_filename=FOREX_DATA_PATH_15MIN\n",
        "# )\n",
        "\n",
        "# env_validation_15min = gym_mtsim.MtEnv(\n",
        "#     original_simulator=sim_validation_15min,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = 10,\n",
        "#     time_points=slices_15min[1],\n",
        "#     hold_threshold=0.5,\n",
        "#     close_threshold=0.5,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim_validation_5min = gym_mtsim.MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=200000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=True,\n",
        "#     symbols_filename=FOREX_DATA_PATH_5MIN\n",
        "# )\n",
        "\n",
        "# env_validation_5min = gym_mtsim.MtEnv(\n",
        "#     original_simulator=sim_validation_5min,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = 10,\n",
        "#     time_points=slices_5min[1],\n",
        "#     hold_threshold=0.5,\n",
        "#     close_threshold=0.5,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim_testing = gym_mtsim.MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=200000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=True,\n",
        "#     symbols_filename=FOREX_DATA_PATH\n",
        "# )\n",
        "\n",
        "# env_testing = MyMtEnv(\n",
        "#     original_simulator=sim_testing,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = 10,\n",
        "#     time_points=slices_1hr[2],\n",
        "#     hold_threshold=0.5,\n",
        "#     close_threshold=0.5,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_stats(reward_over_episodes, printing_name):\n",
        "    \"\"\"  Print Reward  \"\"\"\n",
        "\n",
        "    avg_rewards = np.mean(reward_over_episodes)\n",
        "    min_rewards = np.min(reward_over_episodes)\n",
        "    max_rewards = np.max(reward_over_episodes)\n",
        "\n",
        "    print (f'Min. {printing_name}          : {min_rewards:>10.3f}')\n",
        "    print (f'Avg. {printing_name}          : {avg_rewards:>10.3f}')\n",
        "    print (f'Max. {printing_name}          : {max_rewards:>10.3f}')\n",
        "\n",
        "    return min_rewards, avg_rewards, max_rewards\n",
        "\n",
        "def my_profit_calculation(env_orders, stop_loss):\n",
        "        # env_orders = env_testing.render()['orders']\n",
        "        # stop_loss = 0.001\n",
        "        mean_value = env_orders['Volume'].mean()\n",
        "\n",
        "        # # Normalize the column to have a mean of 1\n",
        "        env_orders.loc[:, 'Volume'] = round((env_orders['Volume'] / mean_value), 2)\n",
        "\n",
        "        # add a column for when the difference between the Entry Price and the Exit Price is greater than stop_loss\n",
        "        env_orders.loc[:, 'stoploss_hit'] = np.where((env_orders['Type'].str.strip() == 'Buy') &\n",
        "                                                        ((env_orders['Entry Price'] - env_orders['Exit Price']) > stop_loss),\n",
        "                                                        1, np.where((env_orders['Type'].str.strip() == 'Sell') &\n",
        "                                                                        ((env_orders['Exit Price'] - env_orders['Entry Price']) > stop_loss),\n",
        "                                                                        1, 0))\n",
        "        env_orders.loc[:, 'Exit Price'] = np.where((env_orders['Type'].str.strip() == 'Buy') & (env_orders['stoploss_hit'] == 1),\n",
        "                                                        env_orders['Entry Price'] - stop_loss,\n",
        "                                                        np.where((env_orders['Type'].str.strip() == 'Sell') & (env_orders['stoploss_hit'] == 1),\n",
        "                                                                env_orders['Entry Price'] + stop_loss, env_orders['Exit Price']))\n",
        "        env_orders.loc[:, 'Profit'] = np.where((env_orders['Type'].str.strip() == 'Buy'),\n",
        "                                                        ((env_orders['Exit Price'] - (env_orders['Fee']/2)) - \n",
        "                                                        (env_orders['Entry Price'] + (env_orders['Fee']/2)))\n",
        "                                                                * 100_000 * env_orders['Volume'], \n",
        "                                                        np.where((env_orders['Type'].str.strip() == 'Sell'),\n",
        "                                                                ((env_orders['Entry Price'] - (env_orders['Fee']/2)) - \n",
        "                                                                (env_orders['Exit Price'] + (env_orders['Fee']/2)))\n",
        "                                                                * 100_000 * env_orders['Volume'], np.nan))\n",
        "        total_reward = env_orders.loc[:, 'Profit'].sum()\n",
        "        # Calculate Gross Profit\n",
        "        gross_profit = env_orders.loc[env_orders['Profit'] > 0, 'Profit'].sum()\n",
        "\n",
        "        # Calculate Gross Loss\n",
        "        gross_loss = env_orders.loc[env_orders['Profit'] < 0, 'Profit'].abs().sum()\n",
        "\n",
        "        # Calculate Profit Factor\n",
        "        profit_factor = gross_profit / gross_loss if gross_loss != 0 else 0\n",
        "\n",
        "        profit_factor = profit_factor - 1\n",
        "\n",
        "        return profit_factor, total_reward\n",
        "\n",
        "# ProgressBarCallback for model.learn()\n",
        "class ProgressBarCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq: int, verbose: int = 1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "\n",
        "    def _on_training_start(self) -> None:\n",
        "        \"\"\"\n",
        "        This method is called before the first rollout starts.\n",
        "        \"\"\"\n",
        "        self.progress_bar = tqdm(total=self.model._total_timesteps, desc=\"model.learn()\")\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            self.progress_bar.update(self.check_freq)\n",
        "        return True\n",
        "    \n",
        "    def _on_training_end(self) -> None:\n",
        "        \"\"\"\n",
        "        This event is triggered before exiting the `learn()` method.\n",
        "        \"\"\"\n",
        "        self.progress_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "space = {\n",
        "    # 'learning_rate': hp.loguniform('learning_rate', -5, -2), # Learning rate\n",
        "    'learning_rate': hp.uniform('learning_rate', 0, 0.04), # Learning rate\n",
        "    'gamma': hp.uniform('gamma', 0.925, 0.975), # Discount factor\n",
        "    # 'ent_coef': hp.loguniform('ent_coef', -5, 0) # Entropy coefficient\n",
        "    'ent_coef': hp.uniform('ent_coef', 0, 0.05), # Entropy coefficient\n",
        "    # 'learning_timesteps': hp.choice('learning_timesteps', [25, 50, 100, 250, 500]),\n",
        "    # 'timeframe': hp.choice('timeframe', ['5min', '15min', '1hr'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAINING + TEST\n",
        "def train_val_model(model, model_policy, env_tr, env_val, seed, steps_str, lr, gamma_param, entropy, total_learning_timesteps=10_000):\n",
        "    \"\"\"\n",
        "    Trains and validates a model using the Proximal Policy Optimization (PPO) algorithm.\n",
        "\n",
        "    Args:\n",
        "        model (object): The model to be trained.\n",
        "        model_policy (object): The policy used by the model.\n",
        "        env_tr (object): The training environment.\n",
        "        env_val (object): The validation environment.\n",
        "        seed (int): The random seed for reproducibility.\n",
        "        steps_str (str): A string representing the number of steps.\n",
        "        window_size_param (int): The window size parameter.\n",
        "        lr (float): The learning rate.\n",
        "        gamma_param (float): The gamma parameter.\n",
        "        entropy (float): The entropy coefficient.\n",
        "        total_learning_timesteps (int, optional): The total number of learning timesteps. Defaults to 10,000.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the reward over validations, orders over validations, and the model dictionary.\n",
        "    \"\"\"\n",
        "    # reproduce training and test\n",
        "    print('-' * 80)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    #model_dict = {}\n",
        "    # env_tr.window_size = window_size_param\n",
        "    print(f'entropy: {entropy}, learning rate: {lr}, gamma: {gamma_param}')\n",
        "    # eval_callback = EvalCallback(env_tr, log_path='./logs/', eval_freq=1000)\n",
        "    obs_tr, info_tr = env_tr.reset(seed=seed)\n",
        "    model = PPO(model_policy, env_tr, verbose=0, ent_coef=entropy, learning_rate=lr)#, gamma=gamma_param, \n",
        "    # custom callback for 'progress_bar'\n",
        "    model.learn(total_timesteps=total_learning_timesteps)#, callback=ProgressBarCallback(100))\n",
        "\n",
        "    reward_over_validations = []\n",
        "    orders_over_validations = []\n",
        "    profit_over_validations = []\n",
        "\n",
        "    for episode in range(0, 10):\n",
        "        obs_val, info_val = env_val.reset(seed=seed)\n",
        "\n",
        "        total_reward = 0\n",
        "        done_val = False\n",
        "\n",
        "        while not done_val:\n",
        "            action, _states = model.predict(obs_val)\n",
        "            obs_val, reward_val, terminated_val, truncated_val, info_val = env_val.step(action)\n",
        "            done_val = terminated_val or truncated_val\n",
        "\n",
        "            total_reward += reward_val\n",
        "            if done_val:\n",
        "                break\n",
        "        try:\n",
        "            orders_made_in_episode = env_val.render()['orders']\n",
        "            order_len = len(orders_made_in_episode)\n",
        "            total_reward, total_profit = my_profit_calculation(orders_made_in_episode, 0.001)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f'There were not any orders produced by the model. Error: {e}')\n",
        "            order_len = 0\n",
        "            total_profit = 0\n",
        "\n",
        "        # model_dict[f'model_{episode}'] = model\n",
        "        # model.save(f'best_hyperparameters/models_4_26_24/model_{episode}.pkl')\n",
        "\n",
        "        reward_over_validations.append(total_reward) \n",
        "        profit_over_validations.append(total_profit)   \n",
        "        orders_over_validations.append(order_len)  \n",
        "\n",
        "\n",
        "        # if episode % 1 == 0:\n",
        "        avg_reward = np.mean(reward_over_validations)\n",
        "        avg_orders = np.mean(orders_over_validations)\n",
        "        avg_profit = np.mean(profit_over_validations)\n",
        "        print(f'Episode: {episode}, Avg. Reward: {avg_reward:.3f}, # of orders: {avg_orders:.3f}, avg Profit: {avg_profit:.3f}')\n",
        "    if np.mean(profit_over_validations) > 0:\n",
        "        model.save(f'models_{max_date_1hr.date()}/model_{steps_str}_{max_date_1hr.date()}.pkl')\n",
        "    return reward_over_validations, orders_over_validations, profit_over_validations#, model_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# create a folder with the name of the date\n",
        "os.makedirs(f'models_{max_date_1hr.date()}', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seed                     : 2024\n"
          ]
        }
      ],
      "source": [
        "seed = 2024  # random seed\n",
        "total_num_episodes = 10\n",
        "\n",
        "# print (\"env_name                 :\", env_name)\n",
        "print (\"seed                     :\", seed)\n",
        "\n",
        "# INIT matplotlib\n",
        "plot_settings = {}\n",
        "plot_data = {'x': [i for i in range(1, total_num_episodes + 1)]}\n",
        "\n",
        "# learning_timesteps_list_in_K = [25]#, 50, 100]\n",
        "# learning_timesteps_list_in_K = [50, 250, 500]\n",
        "# learning_timesteps_list_in_K = [500, 1000, 3000, 5000]\n",
        "\n",
        "# RL Algorithms: https://stable-baselines3.readthedocs.io/en/master/guide/algos.html\n",
        "step_key = 0\n",
        "timesteps_models_dict = {}\n",
        "def objective(params):\n",
        "    learning_timesteps = 100 #params['learning_timesteps']\n",
        "    ent_coef = params['ent_coef']\n",
        "    gamma = params['gamma'] #0.99 #\n",
        "    learning_rate = params['learning_rate']#0.0003#\n",
        "    global step_key\n",
        "\n",
        "    # timeframe = params['timeframe']\n",
        "    # if timeframe == '5min':\n",
        "    #     env_train = env_train_5min\n",
        "    #     env_validation = env_validation_5min\n",
        "    # elif timeframe == '15min':\n",
        "    #     env_train = env_train_15min\n",
        "    #     env_validation = env_validation_15min\n",
        "    # elif timeframe == '1hr':\n",
        "    #     env_train = env_train_1hr\n",
        "    #     env_validation = env_validation_1hr\n",
        "\n",
        "    if learning_rate > 0.08:\n",
        "        print(f'Learning rate too high: {learning_rate}')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "    if ent_coef > 0.1:\n",
        "        print(f'Entropy too high: {ent_coef}')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "\n",
        "    total_learning_timesteps = learning_timesteps * 1000\n",
        "    step_key += 1\n",
        "    policy_dict = PPO.policy_aliases\n",
        "    policy = policy_dict.get('MultiInputPolicy')\n",
        "    class_name = type(PPO).__qualname__\n",
        "    # plot_key = f'{class_name}_rewards_'+step_key\n",
        "    try:\n",
        "        rewards, orders, profits = train_val_model(PPO, policy, env_train_1hr, env_validation_1hr, seed, step_key,  \n",
        "                                                    learning_rate, gamma, ent_coef, total_learning_timesteps)\n",
        "    except Exception as e:\n",
        "        if 'Tensor of shape' in str(e):\n",
        "            print(f'''there was an error with the tensor with those parameters: timesteps: {learning_timesteps}, \\n\n",
        "              ent_coef: {ent_coef}, gamma: {gamma}, learning_rate: {learning_rate}''')\n",
        "        else:\n",
        "            print(f'''there was an error {e} with those parameters: timesteps: {learning_timesteps}, \\n\n",
        "                ent_coef: {ent_coef}, gamma: {gamma}, learning_rate: {learning_rate}''')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "    # timesteps_models_dict[step_key] = models_dict\n",
        "    min_rewards, avg_rewards, max_rewards, = print_stats(profits, 'Profits')\n",
        "    print_stats(orders, 'Orders')\n",
        "    # label = f'Avg. {avg_rewards:>7.2f} : {class_name} - {step_key}'\n",
        "    # plot_data[plot_key] = rewards\n",
        "    # plot_settings[plot_key] = {'label': label}\n",
        "    params['avg_orders'] = np.mean(orders)\n",
        "    params['rewards'] = np.mean(rewards)       \n",
        "\n",
        "    return {'loss': -avg_rewards, 'status': STATUS_OK, 'eval_time': time.time(), 'parameters': params} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # # check if it is working:\n",
        "# parameters = {\n",
        "#     # 'window_size': 10,\n",
        "#     # 'learning_timesteps': 25,\n",
        "#     'ent_coef': 0.008841807731982131,\n",
        "#     # 'gamma': 0.9484679718228304,\n",
        "#     'learning_rate': 0.021173768344759137\n",
        "# }\n",
        "# objective(parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# PPO('MultiInputPolicy', env_train, verbose=0, ent_coef=parameters['ent_coef']).learn(total_timesteps=25_000) #, learning_rate=parameters['learning_rate'], gamma=parameters['gamma'], ent_coef=parameters['ent_coef']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "entropy: 0.00788228517102898, learning rate: 0.024839037799604283, gamma: 0.9657892272238653\n",
            "Episode: 0, Avg. Reward: -0.664, # of orders: 32.000, avg Profit: -687.108\n",
            "Episode: 1, Avg. Reward: -0.376, # of orders: 31.000, avg Profit: -378.250\n",
            "Episode: 2, Avg. Reward: -0.288, # of orders: 30.667, avg Profit: -284.258\n",
            "Episode: 3, Avg. Reward: -0.014, # of orders: 32.000, avg Profit: -71.983\n",
            "Episode: 4, Avg. Reward: 0.003, # of orders: 31.600, avg Profit: -47.957\n",
            "Episode: 5, Avg. Reward: -0.057, # of orders: 31.333, avg Profit: -103.268\n",
            "Episode: 6, Avg. Reward: 0.025, # of orders: 31.857, avg Profit: -32.767\n",
            "Episode: 7, Avg. Reward: -0.019, # of orders: 32.375, avg Profit: -80.627\n",
            "Episode: 8, Avg. Reward: -0.063, # of orders: 31.889, avg Profit: -123.266\n",
            "Episode: 9, Avg. Reward: -0.017, # of orders: 32.200, avg Profit: -76.712\n",
            "Min. Profits          :   -687.108                     \n",
            "Avg. Profits          :    -76.712                     \n",
            "Max. Profits          :    564.842                     \n",
            "Min. Orders          :     28.000                      \n",
            "Avg. Orders          :     32.200                      \n",
            "Max. Orders          :     36.000                      \n",
            "--------------------------------------------------------------------------------    \n",
            "entropy: 0.04662600301793751, learning rate: 0.03466246129179201, gamma: 0.9397037190937831\n",
            "  0%|          | 1/250 [03:52<16:06:06, 232.80s/trial, best loss: 76.71157613027614]"
          ]
        }
      ],
      "source": [
        "#### adding in gamma test ####\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=250, # Number of evaluations of the objective function\n",
        "            trials=trials,\n",
        "            trials_save_file=f'gym_mtsim_forked/examples/hyperopt/trials_5_24_search_next_week.pkl')\n",
        "\n",
        "print(\"Best parameters:\", best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # make a sound when the code is done\n",
        "# import winsound\n",
        "# frequency = 2500  # Set Frequency To 2500 Hertz\n",
        "# duration = 2000  # Set Duration To 1000 ms == 1 second\n",
        "# winsound.Beep(frequency, duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trials_latest_week = pickle.load(open(f'gym_mtsim_forked/examples/hyperopt/trials_5_24_search_next_week.pkl', 'rb'))\n",
        "trials_latest_week_all_results = trials_latest_week.results\n",
        "print(len(trials_latest_week_all_results),\n",
        "trials_latest_week_all_results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparameters_current_week = pd.DataFrame()\n",
        "new_dict = {}\n",
        "for idx, result in enumerate(trials_latest_week_all_results):\n",
        "    new_dict['loss'] = result['loss']\n",
        "    new_dict['status'] = result['status']\n",
        "    new_dict['learning_rate'] = result['parameters']['learning_rate']\n",
        "    new_dict['ent_coef'] = result['parameters']['ent_coef']\n",
        "    new_dict['gamma'] = result['parameters']['gamma']\n",
        "    try:\n",
        "        new_dict['orders'] = result['parameters']['avg_orders']\n",
        "        new_dict['rewards'] = result['parameters']['rewards']\n",
        "    except Exception as e: \n",
        "        new_dict['orders'] = 0\n",
        "        new_dict['rewards'] = 0\n",
        "    new_row = pd.DataFrame(new_dict, index=[idx])\n",
        "    best_hyperparameters_current_week = pd.concat([best_hyperparameters_current_week, new_row], axis=0)\n",
        "best_hyperparameters_current_week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hyperparameters_current_week_success = best_hyperparameters_current_week[best_hyperparameters_current_week['status'] == 'ok']\n",
        "best_hyperparameters_current_week_success_negative = best_hyperparameters_current_week_success[best_hyperparameters_current_week_success['loss'] < 0]\n",
        "best_hyperparameters_current_week_success_negative = best_hyperparameters_current_week_success_negative.sort_values(by='loss', ascending=True)\n",
        "best_hyperparameters_current_week_success_negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_learning_timesteps = 250 * 1_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "custom_palette = sns.color_palette([\"red\", \"green\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def env_fx(slices):\n",
        "    sim_training = gym_mtsim.MtSimulator(\n",
        "        unit='USD',\n",
        "        balance=200000.,\n",
        "        leverage=100.,\n",
        "        stop_out_level=0.2,\n",
        "        hedge=True,\n",
        "        symbols_filename=FOREX_DATA_PATH\n",
        "    )\n",
        "    env_training = gym_mtsim.MtEnv(\n",
        "        original_simulator=sim_training,\n",
        "        trading_symbols=['EURUSD'],\n",
        "        window_size = 10,\n",
        "        time_points= slices[0],\n",
        "        hold_threshold=0.5,\n",
        "        close_threshold=0.5,\n",
        "        fee=lambda symbol: {\n",
        "            # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "            'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "            # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "        }[symbol],\n",
        "        symbol_max_orders=2,\n",
        "        multiprocessing_processes=2\n",
        "    )\n",
        "    sim_validation = gym_mtsim.MtSimulator(\n",
        "        unit='USD',\n",
        "        balance=200000.,\n",
        "        leverage=100.,\n",
        "        stop_out_level=0.2,\n",
        "        hedge=True,\n",
        "        symbols_filename=FOREX_DATA_PATH\n",
        "    )\n",
        "    env_validation = gym_mtsim.MtEnv(\n",
        "        original_simulator=sim_validation,\n",
        "        trading_symbols=['EURUSD'],\n",
        "        window_size = 10,\n",
        "        time_points= slices[1],\n",
        "        hold_threshold=0.5,\n",
        "        close_threshold=0.5,\n",
        "        fee=lambda symbol: {\n",
        "            # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "            'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "            # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "        }[symbol],\n",
        "        symbol_max_orders=2,\n",
        "        multiprocessing_processes=2\n",
        "    )\n",
        "    return env_training, env_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find all of the models that are in the /models_2024_05_17 folder\n",
        "folder_path = f'C:/Users/WilliamFetzner/Documents/Trading/models_{max_date_1hr.date()}'\n",
        "\n",
        "# Get the list of files in the folder\n",
        "file_list = os.listdir(folder_path)\n",
        "file_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the model number from the file name when the file name has the format 'model_##_2024-05-17.pkl' where the ## is the model number\n",
        "model_nums = [x.split('_')[1] for x in file_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test which version of the model to take, does it make a difference whether I use model_0 or model_9\n",
        "seed=2024\n",
        "num_episodes = 1_000\n",
        "\n",
        "total_reward = 0\n",
        "done_test = False\n",
        "reward_over_tests = {}\n",
        "time_now = datetime.now()\n",
        "\n",
        "train_env, env_validation_2 = env_fx(slices_1hr)\n",
        "obs_test, info_test = env_validation_2.reset(seed=seed)\n",
        "obs_tr, info_tr = train_env.reset(seed=seed)\n",
        "\n",
        "for num, model in tqdm(zip(model_nums, file_list)):\n",
        "\n",
        "    # model_ppo = PPO('MultiInputPolicy', train_env, verbose=0, ent_coef=m_ppo_ent_coef, learning_rate=m_ppo_lr, gamma=m_ppo_gamma)\n",
        "    obs_tr, info_tr = train_env.reset(seed=seed)\n",
        "    model_ppo = PPO.load(f'models_{max_date_1hr.date()}/{model}', train_env)\n",
        "    # model_ppo.learn(total_timesteps=total_learning_timesteps, callback=ProgressBarCallback(100))   \n",
        "\n",
        "    rewards = []\n",
        "    for episode in range(num_episodes):\n",
        "        obs_test, info_test = env_validation_2.reset(seed=seed)\n",
        "        # model_ppo = PPO.load(f'gym_mtsim_forked/gym_mtsim/data/model_0.pkl', train_env)\n",
        "        done_test = False\n",
        "        while not done_test:\n",
        "            action, _states = model_ppo.predict(obs_test)\n",
        "            obs_test, reward_test, terminated_test, truncated_test, info_test = env_validation_2.step(action)\n",
        "            done_test = terminated_test or truncated_test\n",
        "            \n",
        "            total_reward += reward_test\n",
        "            if done_test:\n",
        "                break\n",
        "        try:\n",
        "            orders_made_in_episode_test = env_validation_2.render()['orders']\n",
        "            # orders_over_validations_dfs[f'{episode}'] = orders_made_in_episode_test\n",
        "            order_len = len(orders_made_in_episode_test)\n",
        "            total_reward, total_profit = my_profit_calculation(orders_made_in_episode_test, 0.001)\n",
        "            rewards.append(total_profit)\n",
        "        except Exception as e:\n",
        "            print(f'There were not any orders produced by the model. Error = {e}')\n",
        "            rewards.append(0)\n",
        "            order_len = 0\n",
        "    print_stats(rewards, 'Profits')\n",
        "    reward_over_tests[f'model_{num}'] = rewards\n",
        "# print(f'Finished day_{mins} in {int((datetime.now() - time_now).seconds/60)} minutes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(reward_over_tests)\n",
        "# replace any 0s in the dataframe with nans\n",
        "df_nan_replaced = df.replace(0, np.nan)\n",
        "df_nan_replaced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a grid of subplots for every column in df where there are 7 rows and 7 columns that show the distribution of the data\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axs = plt.subplots(nrows=7, ncols=7, figsize=(20, 20))\n",
        "\n",
        "# Flatten the axs array\n",
        "axs = axs.flatten()\n",
        "\n",
        "# Iterate over the columns in df\n",
        "for i, col in enumerate(df.columns):\n",
        "    # Plot the distribution of the column\n",
        "    sns.histplot(data=df, x=col, ax=axs[i])\n",
        "    axs[i].set_title(col)\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "p3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

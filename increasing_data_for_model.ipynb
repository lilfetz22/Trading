{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment forex-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment forex-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment stocks-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment stocks-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment crypto-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment crypto-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment mixed-hedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment mixed-unhedge-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gymnasium as gym\n",
        "import gym_mtsim\n",
        "sys.path.append(\"C:/Users/WilliamFetzner/Documents/Trading/\")\n",
        "from gym_mtsim_forked.gym_mtsim.data import FOREX_DATA_PATH, FOREX_DATA_PATH_1HR, FOREX_DATA_PATH_15MIN, FOREX_DATA_PATH_5MIN\n",
        "from gym_mtsim import OrderType, Timeframe, MtEnv, MtSimulator\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, STATUS_FAIL\n",
        "from stable_baselines3 import A2C, PPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "import time\n",
        "import torch\n",
        "import pickle\n",
        "import fx_rl\n",
        "from datetime import datetime, timedelta\n",
        "import pytz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latest Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now = datetime.now()\n",
        "# current_time = pd.to_datetime(now) + timedelta(hours=7)\n",
        "# current_time = current_time.replace(tzinfo=pytz.UTC)\n",
        "# date_15min = fx_rl.bars_back(current_time, 'M15', total_bars=)\n",
        "# date_5min = fx_rl.bars_back(current_time, 'M5')\n",
        "# date_1hr = fx_rl.bars_back(current_time, 'H1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim = MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=10000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=False,\n",
        "# )\n",
        "# sim.download_data(\n",
        "#     symbols=['EURUSD', 'AUDCHF', 'NZDCHF', 'GBPNZD', 'USDCAD'],\n",
        "#     time_range=(\n",
        "#         date_15min,\n",
        "#         current_time\n",
        "#     ),\n",
        "#     timeframe=Timeframe.M15\n",
        "# )\n",
        "# sim.save_symbols(f'symbols_forex_15min_{date_15min.date()}_{current_time.date()}.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f'symbols_forex_5min_2023-01-09_2024-05-08', 'rb') as f:\n",
        "    symbols_5min = pickle.load(f)\n",
        "# convert symbols_5min to a pd.dataframe\n",
        "symbols_5min[1]['EURUSD'].index = pd.to_datetime(symbols_5min[1]['EURUSD'].index)\n",
        "max_date_5min = symbols_5min[1]['EURUSD'].index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f'symbols_forex_15min_2020-05-11_2024-05-08', 'rb') as f:\n",
        "    symbols_15min = pickle.load(f)\n",
        "# convert symbols_15min to a pd.dataframe\n",
        "symbols_15min[1]['EURUSD'].index = pd.to_datetime(symbols_15min[1]['EURUSD'].index)\n",
        "max_date_15min = symbols_15min[1]['EURUSD'].index.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Timestamp('2024-05-08 13:00:00+0000', tz='UTC')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(f'symbols_forex_1hr_2008-05-19_2024-05-08', 'rb') as f:\n",
        "    symbols_1hr = pickle.load(f)\n",
        "# convert symbols_1hr to a pd.dataframe\n",
        "symbols_1hr[1]['EURUSD'].index = pd.to_datetime(symbols_1hr[1]['EURUSD'].index)\n",
        "# filter the symbols_15min[1]['EURUSD'] to where the index is greater than 2024-3-24\n",
        "one_month_training = symbols_1hr[1]['EURUSD'][symbols_1hr[1]['EURUSD'].index > '2024-01-01']\n",
        "max_date_1hr = one_month_training.index.max()\n",
        "max_date_1hr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # unpack the pickle file and load the data that is in symbols_forex.pkl\n",
        "# with open(FOREX_DATA_PATH, 'rb') as f:\n",
        "#     symbols = pickle.load(f)\n",
        "# # convert symbols to a pd.dataframe\n",
        "# # symbols[1]['EURUSD']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "slices_5min = fx_rl.slices_finder(symbols_5min[1]['EURUSD'], max_date_5min, testing_needed=True)\n",
        "slices_15min = fx_rl.slices_finder(symbols_15min[1]['EURUSD'], max_date_15min, testing_needed=True)\n",
        "slices_1hr = fx_rl.slices_finder(symbols_1hr[1]['EURUSD'], max_date_1hr, testing_needed=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatetimeIndex(['2020-05-11 21:30:00+00:00', '2020-05-11 21:45:00+00:00',\n",
              "               '2020-05-11 22:00:00+00:00', '2020-05-11 22:15:00+00:00',\n",
              "               '2020-05-11 22:30:00+00:00', '2020-05-11 22:45:00+00:00',\n",
              "               '2020-05-11 23:00:00+00:00', '2020-05-11 23:15:00+00:00',\n",
              "               '2020-05-11 23:30:00+00:00', '2020-05-11 23:45:00+00:00',\n",
              "               ...\n",
              "               '2024-05-06 11:15:00+00:00', '2024-05-06 11:30:00+00:00',\n",
              "               '2024-05-06 11:45:00+00:00', '2024-05-06 12:00:00+00:00',\n",
              "               '2024-05-06 12:15:00+00:00', '2024-05-06 12:30:00+00:00',\n",
              "               '2024-05-06 12:45:00+00:00', '2024-05-06 13:00:00+00:00',\n",
              "               '2024-05-06 13:15:00+00:00', '2024-05-06 13:30:00+00:00'],\n",
              "              dtype='datetime64[ns, UTC]', name='Time', length=99255, freq=None)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slices_15min[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatetimeIndex(['2008-05-19 21:00:00+00:00', '2008-05-19 22:00:00+00:00',\n",
              "               '2008-05-19 23:00:00+00:00', '2008-05-20 00:00:00+00:00',\n",
              "               '2008-05-20 01:00:00+00:00', '2008-05-20 02:00:00+00:00',\n",
              "               '2008-05-20 03:00:00+00:00', '2008-05-20 04:00:00+00:00',\n",
              "               '2008-05-20 05:00:00+00:00', '2008-05-20 06:00:00+00:00',\n",
              "               ...\n",
              "               '2024-05-06 04:00:00+00:00', '2024-05-06 05:00:00+00:00',\n",
              "               '2024-05-06 06:00:00+00:00', '2024-05-06 07:00:00+00:00',\n",
              "               '2024-05-06 08:00:00+00:00', '2024-05-06 09:00:00+00:00',\n",
              "               '2024-05-06 10:00:00+00:00', '2024-05-06 11:00:00+00:00',\n",
              "               '2024-05-06 12:00:00+00:00', '2024-05-06 13:00:00+00:00'],\n",
              "              dtype='datetime64[ns, UTC]', name='Time', length=98970, freq=None)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slices_1hr[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyMtEnv(gym_mtsim.MtEnv):\n",
        "    # _get_modified_volume = fx_rl.my_get_modified_volume\n",
        "    _get_prices = fx_rl.my_get_prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def env_fx(timeframe, slices):\n",
        "    if timeframe == '1hr':\n",
        "        data_path = FOREX_DATA_PATH_1HR\n",
        "    elif timeframe == '15min':\n",
        "        data_path = FOREX_DATA_PATH_15MIN\n",
        "    elif timeframe == '5min':\n",
        "        data_path = FOREX_DATA_PATH_5MIN\n",
        "    sim_training = gym_mtsim.MtSimulator(\n",
        "        unit='USD',\n",
        "        balance=200000.,\n",
        "        leverage=100.,\n",
        "        stop_out_level=0.2,\n",
        "        hedge=True,\n",
        "        symbols_filename=data_path\n",
        "    )\n",
        "    env_training = gym_mtsim.MtEnv(\n",
        "        original_simulator=sim_training,\n",
        "        trading_symbols=['EURUSD'],\n",
        "        window_size = 10,\n",
        "        time_points= slices[0],\n",
        "        hold_threshold=0.5,\n",
        "        close_threshold=0.5,\n",
        "        fee=lambda symbol: {\n",
        "            # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "            'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "            # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "        }[symbol],\n",
        "        symbol_max_orders=2,\n",
        "        multiprocessing_processes=2\n",
        "    )\n",
        "    sim_validation = gym_mtsim.MtSimulator(\n",
        "        unit='USD',\n",
        "        balance=200000.,\n",
        "        leverage=100.,\n",
        "        stop_out_level=0.2,\n",
        "        hedge=True,\n",
        "        symbols_filename=data_path\n",
        "    )\n",
        "    env_validation = gym_mtsim.MtEnv(\n",
        "        original_simulator=sim_validation,\n",
        "        trading_symbols=['EURUSD'],\n",
        "        window_size = 10,\n",
        "        time_points= slices[1],\n",
        "        hold_threshold=0.5,\n",
        "        close_threshold=0.5,\n",
        "        fee=lambda symbol: {\n",
        "            # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "            'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "            # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "        }[symbol],\n",
        "        symbol_max_orders=2,\n",
        "        multiprocessing_processes=2\n",
        "    )\n",
        "    return env_training, env_validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# env_validation = MyMtEnv(\n",
        "#     original_simulator=sim_train_1hr,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = 10,\n",
        "#     time_points=slices_1hr[1],\n",
        "#     hold_threshold=0.5,\n",
        "#     close_threshold=0.5,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sim_testing = gym_mtsim.MtSimulator(\n",
        "#     unit='USD',\n",
        "#     balance=200000.,\n",
        "#     leverage=100.,\n",
        "#     stop_out_level=0.2,\n",
        "#     hedge=True,\n",
        "#     symbols_filename=FOREX_DATA_PATH_1HR\n",
        "# )\n",
        "\n",
        "# env_testing = MyMtEnv(\n",
        "#     original_simulator=sim_testing,\n",
        "#     trading_symbols=['EURUSD'],\n",
        "#     window_size = 10,\n",
        "#     time_points=slices_1hr[2],\n",
        "#     hold_threshold=0.5,\n",
        "#     close_threshold=0.5,\n",
        "#     fee=lambda symbol: {\n",
        "#         # 'GBPCAD': max(0., np.random.normal(0.0007, 0.00005)),\n",
        "#         'EURUSD': max(0., np.random.normal(0.0001, 0.00003))\n",
        "#         # 'USDJPY': max(0., np.random.normal(0.02, 0.003)),\n",
        "#     }[symbol],\n",
        "#     symbol_max_orders=2,\n",
        "#     multiprocessing_processes=2\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_stats(reward_over_episodes, printing_name):\n",
        "    \"\"\"  Print Reward  \"\"\"\n",
        "\n",
        "    avg_rewards = np.mean(reward_over_episodes)\n",
        "    min_rewards = np.min(reward_over_episodes)\n",
        "    max_rewards = np.max(reward_over_episodes)\n",
        "\n",
        "    print (f'Min. {printing_name}          : {min_rewards:>10.3f}')\n",
        "    print (f'Avg. {printing_name}          : {avg_rewards:>10.3f}')\n",
        "    print (f'Max. {printing_name}          : {max_rewards:>10.3f}')\n",
        "\n",
        "    return min_rewards, avg_rewards, max_rewards\n",
        "\n",
        "def my_profit_calculation(env_orders, stop_loss):\n",
        "        # env_orders = env_testing.render()['orders']\n",
        "        # stop_loss = 0.001\n",
        "        mean_value = env_orders['Volume'].mean()\n",
        "\n",
        "        # # Normalize the column to have a mean of 1\n",
        "        env_orders.loc[:, 'Volume'] = round((env_orders['Volume'] / mean_value), 2)\n",
        "\n",
        "        # add a column for when the difference between the Entry Price and the Exit Price is greater than stop_loss\n",
        "        env_orders.loc[:, 'stoploss_hit'] = np.where((env_orders['Type'].str.strip() == 'Buy') &\n",
        "                                                        ((env_orders['Entry Price'] - env_orders['Exit Price']) > stop_loss),\n",
        "                                                        1, np.where((env_orders['Type'].str.strip() == 'Sell') &\n",
        "                                                                        ((env_orders['Exit Price'] - env_orders['Entry Price']) > stop_loss),\n",
        "                                                                        1, 0))\n",
        "        env_orders.loc[:, 'Exit Price'] = np.where((env_orders['Type'].str.strip() == 'Buy') & (env_orders['stoploss_hit'] == 1),\n",
        "                                                        env_orders['Entry Price'] - stop_loss,\n",
        "                                                        np.where((env_orders['Type'].str.strip() == 'Sell') & (env_orders['stoploss_hit'] == 1),\n",
        "                                                                env_orders['Entry Price'] + stop_loss, env_orders['Exit Price']))\n",
        "        env_orders.loc[:, 'Profit'] = np.where((env_orders['Type'].str.strip() == 'Buy'),\n",
        "                                                        ((env_orders['Exit Price'] - (env_orders['Fee']/2)) - \n",
        "                                                        (env_orders['Entry Price'] + (env_orders['Fee']/2)))\n",
        "                                                                * 100_000 * env_orders['Volume'], \n",
        "                                                        np.where((env_orders['Type'].str.strip() == 'Sell'),\n",
        "                                                                ((env_orders['Entry Price'] - (env_orders['Fee']/2)) - \n",
        "                                                                (env_orders['Exit Price'] + (env_orders['Fee']/2)))\n",
        "                                                                * 100_000 * env_orders['Volume'], np.nan))\n",
        "        total_reward = env_orders.loc[:, 'Profit'].sum()\n",
        "        # Calculate Gross Profit\n",
        "        gross_profit = env_orders.loc[env_orders['Profit'] > 0, 'Profit'].sum()\n",
        "\n",
        "        # Calculate Gross Loss\n",
        "        gross_loss = env_orders.loc[env_orders['Profit'] < 0, 'Profit'].abs().sum()\n",
        "\n",
        "        # Calculate Profit Factor\n",
        "        profit_factor = gross_profit / gross_loss if gross_loss != 0 else 0\n",
        "\n",
        "        profit_factor = profit_factor - 1\n",
        "\n",
        "        return profit_factor, total_reward\n",
        "\n",
        "# ProgressBarCallback for model.learn()\n",
        "class ProgressBarCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, check_freq: int, verbose: int = 1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "\n",
        "    def _on_training_start(self) -> None:\n",
        "        \"\"\"\n",
        "        This method is called before the first rollout starts.\n",
        "        \"\"\"\n",
        "        self.progress_bar = tqdm(total=self.model._total_timesteps, desc=\"model.learn()\")\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            self.progress_bar.update(self.check_freq)\n",
        "        return True\n",
        "    \n",
        "    def _on_training_end(self) -> None:\n",
        "        \"\"\"\n",
        "        This event is triggered before exiting the `learn()` method.\n",
        "        \"\"\"\n",
        "        self.progress_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "space = {\n",
        "    # 'learning_rate': hp.loguniform('learning_rate', -5, -2), # Learning rate\n",
        "    'learning_rate': hp.uniform('learning_rate', 0, 0.04), # Learning rate\n",
        "    'gamma': hp.uniform('gamma', 0.925, 0.975), # Discount factor\n",
        "    # 'ent_coef': hp.loguniform('ent_coef', -5, 0) # Entropy coefficient\n",
        "    'ent_coef': hp.uniform('ent_coef', 0, 0.05), # Entropy coefficient\n",
        "    # 'learning_timesteps': hp.choice('learning_timesteps', [25, 50, 100, 250, 500]),\n",
        "    'timeframe': hp.choice('timeframe', ['5min', '15min', '1hr']),\n",
        "    'n_bars': hp.uniform('nbars', 24, 100_000)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[96, 192, 288, 384, 480] [24, 48, 72, 96, 120] [288, 576, 864, 1152, 1440]\n",
            "[0, 96, 192, 288, 384] [0, 24, 48, 72, 96] [0, 288, 576, 864, 1152]\n"
          ]
        }
      ],
      "source": [
        "day_max_15min_slices = [96, 192, 288, 384, 480]\n",
        "day_max_1hr_slices = [int(i/4) for i in day_max_15min_slices]\n",
        "day_max_5min_slices = [int(i*12) for i in day_max_1hr_slices]\n",
        "\n",
        "min_15min_slices = [0, 96, 192, 288, 384]\n",
        "min_1hr_slices = [int(i/4) for i in min_15min_slices]\n",
        "min_5min_slices = [int(i*12) for i in min_1hr_slices]\n",
        "\n",
        "print(day_max_15min_slices, day_max_1hr_slices, day_max_5min_slices)\n",
        "print(min_15min_slices, min_1hr_slices, min_5min_slices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAINING + TEST\n",
        "def train_val_model(model, model_policy, seed, steps_str, lr, gamma_param, entropy, timeframe, total_learning_timesteps=10_000):#env_tr, env_val,\n",
        "    \"\"\"\n",
        "    Trains and validates a model using the Proximal Policy Optimization (PPO) algorithm.\n",
        "\n",
        "    Args:\n",
        "        model (object): The model to be trained.\n",
        "        model_policy (object): The policy used by the model.\n",
        "        env_tr (object): The training environment.\n",
        "        env_val (object): The validation environment.\n",
        "        seed (int): The random seed for reproducibility.\n",
        "        steps_str (str): A string representing the number of steps.\n",
        "        window_size_param (int): The window size parameter.\n",
        "        lr (float): The learning rate.\n",
        "        gamma_param (float): The gamma parameter.\n",
        "        entropy (float): The entropy coefficient.\n",
        "        total_learning_timesteps (int, optional): The total number of learning timesteps. Defaults to 10,000.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the reward over validations, orders over validations, and the model dictionary.\n",
        "    \"\"\"\n",
        "    # reproduce training and test\n",
        "    print('-' * 80)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    num_episodes = 10\n",
        "    reward_over_tests = []\n",
        "    orders_over_tests = []\n",
        "    profit_over_tests = []\n",
        "    if timeframe == '5min':\n",
        "        min_slices, day_max_slices = [0, 288, 576, 864, 1152], [288, 576, 864, 1152, 1440]\n",
        "        slices = slices_5min\n",
        "    elif timeframe == '15min':\n",
        "        min_slices, day_max_slices = [0, 96, 192, 288, 384], [96, 192, 288, 384, 480]\n",
        "        slices = slices_15min\n",
        "    elif timeframe == '1hr':\n",
        "        min_slices, day_max_slices = [0, 24, 48, 72, 96], [24, 48, 72, 96, 120]\n",
        "        slices = slices_1hr\n",
        "    \n",
        "    for mins, maxes in zip(min_slices, day_max_slices):\n",
        "        slices_ready = [0, 0]\n",
        "        slices_ready[1] = slices[1][mins:maxes]\n",
        "        timestep_max = slices_ready[1][0]\n",
        "        slices_tmp = slices[1][slices[1] < timestep_max]\n",
        "        slices_ready[0] = slices[0].append(slices_tmp)\n",
        "        \n",
        "        env_tr, env_val = env_fx(timeframe, slices_ready)\n",
        "        obs_test, info_test = env_val.reset(seed=seed)\n",
        "        obs_tr, info_tr = env_tr.reset(seed=seed)\n",
        "        model = PPO(model_policy, env_tr, verbose=0)#, ent_coef=entropy, learning_rate=lr)#, gamma=gamma_param, \n",
        "        \n",
        "        # custom callback for 'progress_bar'\n",
        "        model.learn(total_timesteps=total_learning_timesteps)#, callback=ProgressBarCallback(100))\n",
        "        reward_over_validations = []\n",
        "        orders_over_validations = []\n",
        "        profit_over_validations = []\n",
        "\n",
        "\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            obs_val, info_val = env_val.reset(seed=seed)\n",
        "\n",
        "            total_reward = 0\n",
        "            done_val = False\n",
        "\n",
        "            while not done_val:\n",
        "                action, _states = model.predict(obs_val)\n",
        "                obs_val, reward_val, terminated_val, truncated_val, info_val = env_val.step(action)\n",
        "                done_val = terminated_val or truncated_val\n",
        "\n",
        "                total_reward += reward_val\n",
        "                if done_val:\n",
        "                    break\n",
        "            try:\n",
        "                orders_made_in_episode = env_val.render()['orders']\n",
        "                order_len = len(orders_made_in_episode)\n",
        "                total_reward, total_profit = my_profit_calculation(orders_made_in_episode, 0.001)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f'There were not any orders produced by the model. Error: {e}')\n",
        "                order_len = 0\n",
        "                total_profit = 0\n",
        "\n",
        "            # model_dict[f'model_{episode}'] = model\n",
        "            # model.save(f'best_hyperparameters/models_4_26_24/model_{episode}.pkl')\n",
        "\n",
        "            reward_over_validations.append(total_reward) \n",
        "            profit_over_validations.append(total_profit)   \n",
        "            orders_over_validations.append(order_len)  \n",
        "\n",
        "\n",
        "            # if episode % 1 == 0:\n",
        "            avg_reward = np.mean(reward_over_validations)\n",
        "            avg_orders = np.mean(orders_over_validations)\n",
        "            avg_profit = np.mean(profit_over_validations)\n",
        "            print(f'Episode: {episode}, Avg. Reward: {avg_reward:.3f}, # of orders: {avg_orders:.3f}, avg Profit: {avg_profit:.3f}')\n",
        "        reward_over_tests[f'{mins}'] = reward_over_validations\n",
        "        orders_over_tests[f'{mins}'] = orders_over_validations\n",
        "        profit_over_tests[f'{mins}'] = profit_over_validations\n",
        "        # get the average reward, orders, and profit for the week by finding the mean of the reward_over_tests, orders_over_tests, and profit_over_tests dictionaries\n",
        "        avg_reward_week = np.sum([np.sum(reward_over_tests[key]) for key in reward_over_tests.keys()])/(num_episodes*len(reward_over_tests.keys()))\n",
        "        avg_orders_week = np.sum([np.sum(orders_over_tests[key]) for key in orders_over_tests.keys()])/(num_episodes*len(orders_over_tests.keys()))\n",
        "        avg_profit_week = np.sum([np.sum(profit_over_tests[key]) for key in profit_over_tests.keys()])/(num_episodes*len(profit_over_tests.keys()))\n",
        "        min_profit_week = np.sum([np.min(profit_over_tests[key]) for key in profit_over_tests.keys()])\n",
        "        max_profit_week = np.sum([np.max(profit_over_tests[key]) for key in profit_over_tests.keys()])\n",
        "\n",
        "        print(f'Avg Profit for Week: {avg_profit_week:.3f}, Min Profit for Week: {min_profit_week:.3f}, Max Profit for Week: {max_profit_week:.3f}')\n",
        "\n",
        "    return avg_reward_week, avg_orders_week, avg_profit_week#, model_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seed                     : 2024\n"
          ]
        }
      ],
      "source": [
        "seed = 2024  # random seed\n",
        "total_num_episodes = 10\n",
        "\n",
        "# print (\"env_name                 :\", env_name)\n",
        "print (\"seed                     :\", seed)\n",
        "\n",
        "# INIT matplotlib\n",
        "plot_settings = {}\n",
        "plot_data = {'x': [i for i in range(1, total_num_episodes + 1)]}\n",
        "\n",
        "# learning_timesteps_list_in_K = [25]#, 50, 100]\n",
        "# learning_timesteps_list_in_K = [50, 250, 500]\n",
        "# learning_timesteps_list_in_K = [500, 1000, 3000, 5000]\n",
        "\n",
        "# RL Algorithms: https://stable-baselines3.readthedocs.io/en/master/guide/algos.html\n",
        "\n",
        "timesteps_models_dict = {}\n",
        "def objective(params):\n",
        "    learning_timesteps = 100 #params['learning_timesteps']\n",
        "    ent_coef = params['ent_coef']#0#\n",
        "    gamma = params['gamma'] #0.99 #\n",
        "    learning_rate = params['learning_rate']#0.0003#\n",
        "    # bars = params['n_bars']\n",
        "    timeframe = params['timeframe']\n",
        "    print(f'----- timeframe: {timeframe} ------')\n",
        "    total_learning_timesteps = learning_timesteps * 1000\n",
        "    step_key = f'{learning_timesteps}K'\n",
        "    policy_dict = PPO.policy_aliases\n",
        "    policy = policy_dict.get('MultiInputPolicy')\n",
        "    class_name = type(PPO).__qualname__\n",
        "    plot_key = f'{class_name}_rewards_'+step_key\n",
        "    try:\n",
        "        avg_rewards, avg_orders, avg_profits = train_val_model(PPO, policy, seed, step_key,  \n",
        "                                                    learning_rate, gamma, ent_coef, timeframe, total_learning_timesteps)\n",
        "    except Exception as e:\n",
        "        print(f'''there was an error {e} with those parameters: timesteps: {learning_timesteps}, \\n\n",
        "              ent_coef: {ent_coef}, gamma: {gamma}, learning_rate: {learning_rate}''')\n",
        "        return {'loss': None, 'status': STATUS_FAIL, 'eval_time': time.time(), 'parameters': params}\n",
        "    # timesteps_models_dict[step_key] = models_dict\n",
        "    # min_rewards, avg_rewards, max_rewards, = print_stats(rewards, 'Reward')\n",
        "    # print_stats(orders, 'Orders')\n",
        "    # label = f'Avg. {avg_rewards:>7.2f} : {class_name} - {step_key}'\n",
        "    # plot_data[plot_key] = rewards\n",
        "    # plot_settings[plot_key] = {'label': label}\n",
        "    params['avg_orders'] = avg_orders\n",
        "    params['profits'] = avg_rewards       \n",
        "\n",
        "    return {'loss': -avg_profits, 'status': STATUS_OK, 'eval_time': time.time(), 'parameters': params} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### adding in gamma test ####\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=200, # Number of evaluations of the objective function\n",
        "            trials=trials,\n",
        "            trials_save_file=f'gym_mtsim_forked/examples/hyperopt/trials_5_16_timeframe_analysis_daily_retraining.pkl')\n",
        "\n",
        "print(\"Best parameters:\", best)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "p3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

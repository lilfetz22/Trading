{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime as dt\n",
    "import mplfinance \n",
    "import fx\n",
    "\n",
    "from collections import deque\n",
    "from renkodf import Renko\n",
    "from scipy.signal import lfilter\n",
    "from deap import base, creator, tools\n",
    "from scipy.stats import zscore\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:00:12.108</th>\n",
       "      <td>1.10427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:00:14.513</th>\n",
       "      <td>1.10425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:00:18.925</th>\n",
       "      <td>1.10425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:00:25.498</th>\n",
       "      <td>1.10425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:00:36.129</th>\n",
       "      <td>1.10429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:00:44.956</th>\n",
       "      <td>1.10425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:00:54.534</th>\n",
       "      <td>1.10429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:01:04.364</th>\n",
       "      <td>1.10429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:01:08.324</th>\n",
       "      <td>1.10429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 17:01:08.626</th>\n",
       "      <td>1.10429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           close\n",
       "datetime                        \n",
       "2024-01-01 17:00:12.108  1.10427\n",
       "2024-01-01 17:00:14.513  1.10425\n",
       "2024-01-01 17:00:18.925  1.10425\n",
       "2024-01-01 17:00:25.498  1.10425\n",
       "2024-01-01 17:00:36.129  1.10429\n",
       "2024-01-01 17:00:44.956  1.10425\n",
       "2024-01-01 17:00:54.534  1.10429\n",
       "2024-01-01 17:01:04.364  1.10429\n",
       "2024-01-01 17:01:08.324  1.10429\n",
       "2024-01-01 17:01:08.626  1.10429"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the actual data from csv file\n",
    "filename = \"C:/Users/WilliamFetzner/Documents/Trading/EURUSD1.csv\"\n",
    "tickstory_filename = \"C:/Users/WilliamFetzner/Documents/Trading/3mo_EURUSD.csv\"\n",
    "df_tick = pd.read_csv(tickstory_filename)\n",
    "df_tick['datetime'] = pd.to_datetime(df_tick['Timestamp'], format='%Y%m%d %H:%M:%S:%f')\n",
    "# rename bid price to close\n",
    "df_tick.rename(columns={'Bid price':'close'}, inplace=True)\n",
    "df_tick.set_index('datetime', inplace=True)\n",
    "df_tick_ready = df_tick[['close']]\n",
    "df_tick_ready_2024 = df_tick_ready['2024-01-01':'2024-02-13']\n",
    "# df_full = pd.read_csv(filename, header=None, names=['date', 'time', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df_tick_ready_2024.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime\n",
    "# df_full['datetime'] = pd.to_datetime(df_full['date'] + ' ' + df_full['time'], format='%Y.%m.%d %H:%M')\n",
    "# filter the data to just 2023\n",
    "\n",
    "# df_2022 = fx.prep_data(df_full, 2022)\n",
    "# df_2023 = fx.prep_data(df_full, 2023)\n",
    "# df_2024 = fx.prep_data(df_full, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renko variable\n",
    "initial_brick_size = 0.0001\n",
    "# create a list of possible brick sizes a max at 0.001 and min at 0.00001 and each step is 0.00001\n",
    "brick_size_list = np.arange(0.00007, 0.00101, 0.00001)\n",
    "# get one random brick size\n",
    "brick_size = np.random.choice(brick_size_list)\n",
    "\n",
    "# psar variables\n",
    "start = 0.02\n",
    "increment = 0.02\n",
    "increment_list = np.arange(0.001, 0.2001, 0.0001)\n",
    "maximum = 0.2\n",
    "max_list = np.arange(0.01, 0.501, 0.001)\n",
    "\n",
    "# impulse variables\n",
    "lengthMA = 34\n",
    "ma_list = np.arange(10, 100, 1)\n",
    "lengthSignal = 9\n",
    "signal_list = np.arange(1, 51, 1)\n",
    "\n",
    "# Lot Size\n",
    "initial_lot_size = 5\n",
    "lot_sizes_list = np.arange(1, 5, 1)\n",
    "per_lot = 100000\n",
    "\n",
    "# Commissions\n",
    "nova_commission = -3\n",
    "msolutions_commission = -5\n",
    "\n",
    "# starting balance\n",
    "balance = 200000\n",
    "\n",
    "# base currency rate\n",
    "base_currency_rate = 0.045 # EUR\n",
    "quote_currency_rate = 0.055 # USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renko_ready(df, brick_size):\n",
    "    # create a renko chart from the df dataframe\n",
    "    r_full = Renko(df, brick_size=brick_size)\n",
    "    # create a new dataframe from the renko features\n",
    "    renko_data = r_full.renko_df()\n",
    "    return renko_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_cols(df, inc, max, ma, signal, stop_loss):\n",
    "    # adding psar to the dataframe\n",
    "    r_w_psar = fx.psar_from_data(df, inc, max)\n",
    "    # adding impulse to the dataframe\n",
    "    r_w_impulse = fx.calc_impulse_macd(r_w_psar, ma, int(signal))\n",
    "    # add the brick color to the dataframe\n",
    "    r_w_impulse['brick_color'] = np.where(r_w_impulse['open'] > r_w_impulse['close'], 'red', 'green')\n",
    "    # add the day of the week to the dataframe\n",
    "    r_w_impulse['day_of_week'] = r_w_impulse.index.day_name()\n",
    "    # place a 1 in day_of_week_transition, if it is the last bar on Friday and the next bar is Sunday\n",
    "    r_w_impulse['day_of_week_transition'] = np.where((r_w_impulse['day_of_week'] == 'Friday') & \n",
    "                                                     ((r_w_impulse['day_of_week'].shift(-1) == 'Sunday') | (r_w_impulse['day_of_week'].shift(-1) == 'Monday')), 1, 0)\n",
    "\n",
    "    #### entry conditions ####\n",
    "    # add a column that will be the entry signal for the strategy to be when both impulse_signal and psar_signal are both 'buy' or 'sell'\n",
    "    r_w_impulse['entry_signal'] = np.where((r_w_impulse['psar_signal'] == 'buy') & (r_w_impulse['impulse_signal'] == 'buy') \n",
    "                                            & (r_w_impulse['brick_color'] == 'green') & (r_w_impulse['day_of_week_transition'] != 1), 'long', \n",
    "                                            np.where((r_w_impulse['psar_signal'] == 'sell') & (r_w_impulse['impulse_signal'] == 'sell') & \n",
    "                                                    (r_w_impulse['brick_color'] == 'red') & (r_w_impulse['day_of_week_transition'] != 1), 'short', 'none'))\n",
    "\n",
    "    # if there was a change from 'none' to 'buy' or 'sell' then that is an entry signal and replace the 'buy' or 'sell' with 'entry + long' or 'entry + sell'\n",
    "    r_w_impulse['entry_signal'] = np.where((r_w_impulse['entry_signal'] != 'none') & (r_w_impulse['entry_signal'].shift(1) == 'none'),\n",
    "                                                'entry + ' + r_w_impulse['entry_signal'], r_w_impulse['entry_signal'])\n",
    "\n",
    "    #### Exit conditions ####\n",
    "    # add a stop loss column that will be the entry price +/- the brick size for when the entry signal is 'entry + long' or 'entry + sell'\n",
    "    r_w_impulse['stop_loss'] = np.where(r_w_impulse['entry_signal'] == 'entry + long', r_w_impulse['open'] - stop_loss,\n",
    "                                            np.where(r_w_impulse['entry_signal'] == 'entry + short', r_w_impulse['open'] + stop_loss, np.nan))\n",
    "    \n",
    "    # if the 'entry_signal' colummn goes from 'entry + short' or 'short' to 'none' then 'none' should be replaced with 'exit' in the entry_signal column\n",
    "    r_w_impulse['entry_signal'] = np.where((r_w_impulse['entry_signal'].shift(1) == 'entry + short') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                np.where((r_w_impulse['entry_signal'].shift(1) == 'short') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                        np.where((r_w_impulse['entry_signal'].shift(1) == 'entry + long') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                                np.where((r_w_impulse['entry_signal'].shift(1) == 'long') & (r_w_impulse['entry_signal'] == 'none'), 'exit', \n",
    "                                                                        r_w_impulse['entry_signal']))))\n",
    "    # position_count will be a cumulative count used to filter the data to the timeframe between the entry \n",
    "    # and exit signals so anytime there is an \"entry + long\" or \"entry + short\" the count should increase by 1\n",
    "    r_w_impulse['position_count'] = np.where(r_w_impulse['entry_signal'] == 'entry + long', 1, np.where(r_w_impulse['entry_signal'] == 'entry + short', 1, 0))\n",
    "    r_w_impulse['cum_position_count'] = r_w_impulse['position_count'].cumsum()\n",
    "    # when 'entry_signal' is 'none' then the 'cum_position_count' should be null\n",
    "    r_w_impulse['cum_position_count'] = np.where(r_w_impulse['entry_signal'] == 'none', np.nan, r_w_impulse['cum_position_count'])\n",
    "    # group by cum_position_count and forward fill the value in the first index of the 'stop_loss' column\n",
    "    r_w_impulse['stop_loss'] = r_w_impulse.groupby('cum_position_count')['stop_loss'].ffill()\n",
    "    # determine whether the exit should be sooner because the stop_loss was hit before the exit signal (look at the high/low of the brick)\n",
    "    r_w_impulse['exit_stop_loss'] = np.where((r_w_impulse['entry_signal'] == 'long') & (r_w_impulse['stop_loss'] > r_w_impulse['low']), 1,\n",
    "                                            np.where((r_w_impulse['entry_signal'] == 'short') & (r_w_impulse['stop_loss'] < r_w_impulse['high']), 1, 0))\n",
    "    \n",
    "    return r_w_impulse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_profit_loss(df, lots):\n",
    "    profit_df = pd.DataFrame() #columns=['cum_position_count', 'direction', 'entry_price', 'exit_price', 'first_TP_hit', 'profit']\n",
    "# calculate the profit for each position by first grouping by each position and finding the entry price\n",
    "    profit_df['entry_price'] = df.groupby('cum_position_count')['close'].first()\n",
    "    # separate out the datetime column\n",
    "    df['datetime'] = df.index\n",
    "    # get the entry and exit times\n",
    "    profit_df['entry_time'] = df.groupby('cum_position_count')['datetime'].first()\n",
    "    profit_df['exit_time'] = df.groupby('cum_position_count')['datetime'].last()\n",
    "    # # determine the exit price\n",
    "    profit_df['exit_price'] = df.groupby('cum_position_count')['close'].last()\n",
    "    # # what was the direction, long or short?\n",
    "    profit_df['direction'] = df.groupby('cum_position_count')['entry_signal'].first()\n",
    "    profit_df['direction'] = profit_df['direction'].str.split('+').str[1]\n",
    "    profit_df['profit'] = np.where((profit_df['direction'].str.strip() == 'long'),\n",
    "                                            (profit_df['exit_price'] - profit_df['entry_price'])*per_lot*(lots), \n",
    "                                            np.where((profit_df['direction'].str.strip() == 'short'),\n",
    "                                                    (profit_df['entry_price'] - profit_df['exit_price'])*per_lot*(lots), np.nan))\n",
    "    profit_df = fx.add_swap_rates(profit_df, base_currency_rate, quote_currency_rate, lots=lots)\n",
    "    profit_df['nova_profit'] = profit_df['profit'] + (nova_commission*lots) + profit_df['swap_rate']\n",
    "    profit_df['msolutions_profit'] = profit_df['profit'] + (msolutions_commission*lots) + profit_df['swap_rate']\n",
    "    # use the entry time and resample to each day and find the sum of the profit\n",
    "    profit_df['entry_time'] = pd.to_datetime(profit_df['entry_time'])\n",
    "    profit_df_new_index = profit_df.set_index('entry_time')\n",
    "    # find the sum of the nova and msolutions profit for each day\n",
    "    profit_df_daily = profit_df_new_index.resample('D').agg({'nova_profit': 'sum'})\n",
    "    # drop the weekends by first adding in a new day of the week column\n",
    "    profit_df_daily['day_of_week'] = profit_df_daily.index.day_name()\n",
    "    # drop any day that is Saturday or Sunday\n",
    "    profit_df_daily = profit_df_daily.loc[(profit_df_daily['day_of_week'] != 'Saturday') & (profit_df_daily['day_of_week'] != 'Sunday')]\n",
    "    # find the number of times that profit_df_daily is below zero\n",
    "    profit_df_daily['nova_negative'] = np.where(profit_df_daily['nova_profit'] < 0, 1, 0)\n",
    "    # find the sum of nova_negative and msolutions_negative\n",
    "    nova_negative_sum = profit_df_daily['nova_negative'].sum()\n",
    "    # find the sum of nova_profit\n",
    "    nova_profit_sum = profit_df['nova_profit'].sum()\n",
    "\n",
    "    return nova_profit_sum, nova_negative_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_calculations(df, brick_size, inc, max, ma, signal, stop_loss, lot_size):\n",
    "    renko_data = renko_ready(df, brick_size)\n",
    "    # add the columns necessary for the strategy\n",
    "    renko_data_cols_added = adding_cols(renko_data, inc, max, ma, signal, stop_loss)\n",
    "    # determine the profit/loss for the strategy\n",
    "    total_profit, days_in_drawdown = calc_profit_loss(renko_data_cols_added, lot_size)\n",
    "\n",
    "    return total_profit, days_in_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max date of df_2024 \n",
    "# df_2024.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for standard values\n",
    "# print('2022 data: ', making_calculations(df_2022, initial_brick_size, start, maximum, lengthMA, lengthSignal, initial_brick_size*2, initial_lot_size))\n",
    "# print('2023 data: ', making_calculations(df_2023, initial_brick_size, start, maximum, lengthMA, lengthSignal, initial_brick_size*2, initial_lot_size))\n",
    "# print('2024 data: ', making_calculations(df_2024, initial_brick_size, start, maximum, lengthMA, lengthSignal, initial_brick_size*2, initial_lot_size))\n",
    "# print('last 3 months data: ', making_calculations(df_tick_ready, initial_brick_size, start, maximum, lengthMA, lengthSignal, initial_brick_size*2, initial_lot_size))\n",
    "# 2022 data:  ($1,136,669.99, 53)\n",
    "# 2023 data:  ($447,824.99, 82)\n",
    "# 2024 data:  ($20,509.99, 15)\n",
    "# last 3 months data:  (23,329.99, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = [brick_size_list, increment_list, max_list, ma_list, signal_list] # , lot_sizes_list,  \n",
    "def constraint_handler(individual):\n",
    "    counter = 0\n",
    "    for i, lst in zip(individual, lol):\n",
    "        # Ensure parameter is greater than   0\n",
    "        if i <= 0:\n",
    "            individual[counter] = np.random.choice(lst)  # Reset to a valid value\n",
    "        counter += 1\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e944f229cc48fa99c518796fd1ac36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WilliamFetzner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\renkodf\\renkodf.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"datetime\"] = df.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006199999999999999 0.15890000000000007 0.20899999999999985 69 40\n",
      "1\n",
      "0.0006899999999999999 0.05090000000000002 0.16199999999999987 85 1\n",
      "2\n",
      "0.001 0.16870000000000007 0.18899999999999986 96 50\n",
      "3\n",
      "0.00049 0.06240000000000003 0.28499999999999975 34 42\n",
      "4\n",
      "0.0003399999999999999 0.07530000000000003 0.2499999999999998 52 43\n"
     ]
    }
   ],
   "source": [
    "# Define the fitness function\n",
    "import sys\n",
    "# Check if FitnessMax already exists in the __main__ namespace\n",
    "if 'FitnessMax' not in sys.modules['__main__'].__dict__:\n",
    "    # If not, create it\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "\n",
    "if 'Individual' not in sys.modules['__main__'].__dict__:\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "# creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "# creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "population_size = 100\n",
    "global_total_profits = []  # A list to collect total profits from all individuals\n",
    "global_days_in_drawdowns = []  # A list to collect days in drawdown from all individuals\n",
    "# Global variables to keep track of the number of evaluations\n",
    "num_evaluations = 0\n",
    "discard_threshold = 20  # Discard the first 20 evaluations\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Register an attribute generator for each parameter with its own range\n",
    "toolbox.register(\"brick_size\", np.random.choice, brick_size_list)\n",
    "toolbox.register(\"increment\", np.random.choice, increment_list)\n",
    "toolbox.register(\"maximum\", np.random.choice, max_list)\n",
    "toolbox.register(\"ma\", np.random.choice, ma_list)\n",
    "toolbox.register(\"signal\", np.random.choice, signal_list)\n",
    "# toolbox.register(\"lot_size\", np.random.choice, lot_sizes_list)\n",
    "\n",
    "# Combine the attribute generators to create an individual\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                  (toolbox.brick_size, toolbox.increment, toolbox.maximum,\n",
    "                   toolbox.ma, toolbox.signal))# , toolbox.lot_size, \n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "def eval_func(individual):\n",
    "    # Assuming these are global variables accessible within the scope of eval_func\n",
    "    global global_total_profits  # A list to collect total profits from all individuals\n",
    "    global global_days_in_drawdowns  # A list to collect days in drawdown from all individuals\n",
    "    global num_evaluations  # A global variable to keep track of the number of evaluations\n",
    "\n",
    "    # Unpack individual parameters\n",
    "    brick_size, inc, max, ma, signal = individual #, lot_size, brick_size\n",
    "    print(brick_size, inc, max, ma, signal) # , lot_size, brick_size\n",
    "    for i in individual:\n",
    "        if i <= 0:\n",
    "            individual = constraint_handler(individual)\n",
    "            brick_size,inc, max, ma, signal = individual #, lot_size,\n",
    "            print(brick_size, inc, max, ma, signal) #, lot_size, \n",
    "\n",
    "    # Perform calculations using these parameters\n",
    "    total_profit, days_in_drawdown = making_calculations(df_tick_ready_2024, brick_size, inc, max, ma, signal, brick_size*2, initial_lot_size)\n",
    "\n",
    "    # Update the global lists with the new values\n",
    "    global_total_profits.append(total_profit)\n",
    "    # print(global_total_profits)\n",
    "    global_days_in_drawdowns.append(days_in_drawdown)\n",
    "\n",
    "    if len(global_total_profits) > discard_threshold:\n",
    "        # Normalize total_profit and days_in_drawdown independently\n",
    "        norm_total_profit = zscore(global_total_profits)[-1]\n",
    "        norm_days_in_drawdown = zscore(global_days_in_drawdowns)[-1]\n",
    "        # Combine the scores\n",
    "        score = norm_total_profit - norm_days_in_drawdown\n",
    "        print(score)\n",
    "        return (score,)\n",
    "    else:\n",
    "        num_evaluations +=  1\n",
    "        print(num_evaluations)\n",
    "        return (0,)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "toolbox.register(\"evaluate\", eval_func)\n",
    "\n",
    "# Define the feasibility function\n",
    "def feasible(individual):\n",
    "    for i, lst in zip(individual, lol):\n",
    "        # find the min of the list\n",
    "        min = lst.min()\n",
    "        # find the max of the list\n",
    "        max = lst.max()\n",
    "        if i < min or i > max:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Define a distance function to the feasibility region\n",
    "def distance(individual):\n",
    "    distances = 0\n",
    "    for i, lst in zip(individual, lol):\n",
    "        # find the min of the list\n",
    "        min = lst.min()\n",
    "        # find the max of the list\n",
    "        max = lst.max()\n",
    "        if i < min:\n",
    "            # find out how far away from the min the parameter is and then normalize it\n",
    "            dist = abs(i - min) / (max - min)\n",
    "        elif i > max:\n",
    "            # find out how far away from the max the parameter is and then normalize it\n",
    "            dist = abs(i - max) / (max - min)\n",
    "        else:\n",
    "            dist = 0\n",
    "        distances += dist\n",
    "    return distances  # Distance from the feasibility region\n",
    "\n",
    "# Decorate the evaluation function with a DeltaPenalty decorator\n",
    "toolbox.decorate(\"evaluate\", tools.DeltaPenalty(feasible, 1.0, distance))\n",
    "toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "# toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=0.00001, up=0.00101, eta=20.0, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "# Register the population and other operators as before\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)\n",
    "\n",
    "# Create initial population\n",
    "population = toolbox.population(n=population_size)\n",
    "for ind in population:\n",
    "    ind.fitness.values = (0,)  # Temporary fitness value\n",
    "\n",
    "# Run the genetic algorithm\n",
    "NGEN =  50  # Number of generations\n",
    "CXPB =  0.7  # Crossover probability\n",
    "MUTPB =  0.2  # Mutation probability\n",
    "\n",
    "for gen in tqdm(range(NGEN)):\n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if ind.fitness.values == (0,)]\n",
    "    # print(invalid_ind)\n",
    "    invalid_ind.extend([ind for ind in offspring if not ind.fitness.valid])\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        # print(type(ind.fitness.values[0]), ind.fitness.values, type(fit), fit)\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Replace population with the offspring\n",
    "    population[:] = offspring\n",
    "\n",
    "# Extract the best individual\n",
    "best_ind = tools.selBest(population,  1)[0]\n",
    "best_score = best_ind.fitness.values[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10990000000000005, 0.2439999999999998, 10.790947339263093, 3.737068524266502] 1.0405709781660026\n"
     ]
    }
   ],
   "source": [
    "print(best_ind, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_brick, best_inc, best_max, best_ma, best_signal = best_ind #, best_lot_size,  \n",
    "results_3mo = making_calculations(df_tick_ready_2024, initial_brick_size, best_inc, best_max, best_ma, best_signal, initial_brick_size*2, initial_lot_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_2023 = making_calculations(df_2023, initial_brick_size, best_inc, best_max, best_ma, best_signal, initial_brick_size*2, initial_lot_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_2024 = making_calculations(df_2024, initial_brick_size, best_inc, best_max, best_ma, best_signal, initial_brick_size*2, initial_lot_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the best_parameters_IP.xlsx file\n",
    "best_parameters = pd.read_excel('C:/Users/WilliamFetzner/Documents/Trading/best_parameters_IP.xlsx')\n",
    "# create a new row with the best parameters\n",
    "new_row_added = pd.concat([best_parameters, pd.DataFrame({'best_brick': [best_brick], 'best_inc': [best_inc], 'best_max': [best_max], 'best_ma': [best_ma], 'best_signal': [best_signal],\n",
    "           'lot_size': [initial_lot_size], 'lot size options': 'set to 5', '2024': [0], '2023': [0], \n",
    "           '2022': [0], '3 months': results_3mo[0]})], ignore_index=True)\n",
    "# save the best_parameters dataframe to the best_parameters_IP.xlsx file\n",
    "new_row_added.to_excel('C:/Users/WilliamFetzner/Documents/Trading/best_parameters_IP.xlsx', index=False)\n",
    "new_row_added"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

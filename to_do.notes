# Variables to adjust:

# type "newday"

## IMPULSE MACD and PSAR
1. Renko Brick Size
2. 15 min chart or Renko chart
3. Renko and just PSAR? or Renko, PSAR, and Impulse? 
4. When to exit? 
    a. Vu's strategy (one renko brick in same direction, take half, set SL to 0, then exit on Renko bar reversal)
    b. one renko brick in same direction, take half, set SL to 0, then exit at n fib levels above entry (optimize n)
5. When to Enter?
    a. PSAR and Impulse
    b. PSAR only
    c. Impulse only
5. Optimize inputs into PSAR and Impulse
6. What would happen if I didn't take half after one renko brick in same direction? 
    

## Things to investigate
1. Weekend holds - DONE
2. Max daily drawdown = -$4,500 -> start Nova at 5 lot size, Msolutions is good for 10 lot size
3. Swap rates - DONE
4. Rejoin with original data to see if high's and low's are correct - DONE
5. find out how often the input data skips minutes - 0.5% of the time, there are 98 instances of 121 min gaps, then several 60 min gaps, 1814 gaps in total that are greater than 1 min - DONE
6. Create an optimization function for each of the parameters
    a. Check how well the hours for turning off IP extend to new data
    b. calculate win rate - DONE
    c. how often do the parameters need to be refreshed? 
        - say I optimized the parameters on the last 4 months of data, then applied them to the next week, did it perform significantly better than just using the full year's parameters? 
    d. make sure the optimization function negatively imposes constraints for any value outside of the original bounds of each list and will ask for a new sample if the value is impossible and will throw an error in the making_calculations function. - DONE
7. figure out how to add in the Max payout to the notebook
8. integrate news events to not take any trades in the bot 5 minutes before and after the news event - DONE




## Next Steps:
1. See if I can connect to MetaTrader 5 and run this strategy on a demo account - NOT POSSIBLE
      - after I get the impulse_psar working on MT4, then I can only choose brokers who offer MT5 (Nova) and transition over in the future
2. If that doesn't work, then see if I can translate this strategy to create a Expert Advisor in MetaTrader 4

## EA in MetaTrader 4
1. Get Renko bars on the chart and then be able to extract their values
     - determine how far back the indicator stores values that can be accessed by the EA for PSAR and Impulse
2. replicate the PSAR function - DONE found an indicator that does this
3. replicate the Impulse MACD function - DONE found an indicator that does this
4. figure out how to test EA on historical data - DONE
5. Define Entry Conditions - DONE
6. Define Exit Conditions - DONE
7. Define S/L - DONE
8. Define primary and secondary T/P - DONE
9. Add in calculations for the psar and impulse MACD so I'm not depending on the indicators
10. integrate news events to not take any trades in the bot 5 minutes before and after the news event - DONE
11. Make lot size adjustable to where it takes into account the average loss and the balance of the account so that we can make 4 consecutive losses and not go under the Max_drawdown limit
    a. otherwise if max_drawdown is not a problem, then take the average lot size * 2 and use the integer value of that as the lot size - DONE
12. find out the profit for running IP for the entire year
    a. calculate the win_rate per hour - DONE
    b. Use this to adjust the lot_size
13. Create the pseudo take profit with the closing being after 3 bars that are relatively level

## Debugging:
1. there is still an error with some of the tickets opening when others are still open.  - fixed
2. I need to either protect against errors in Impulse MACD when the Impulse was Null and the Signal was 0.0088 because that will cause the EA to open shorts even though it shouldn't - this is fine

# Steps to add the EA to the chart
1. Open EURUSD 1 min chart
2. Drag Renko EA onto the chart
3. Make sure that live trading is enabled
4. Open offline EURUSD 2 chart
5. Uncheck "offline chart" in the properties
6. Drag the Parabolic SAR and Impulse MACD indicators onto the chart
7. Drag Impulse_PSAR EA onto the chart
8. Make sure that live trading is enabled


## Changes to make EA match the backtest
1. change start time from 3 to 4 am and end time to 4 pm - DONE
2. Handling news events (no new trades 1 hr after news event) - DONE
3. making it where the PSAR has to switch before initiating a new trade - DONE


# New Strategy
Shift everything to just straight python. I have a new connector that will allow me to run python code with a EA in MT4: 
https://github.com/TheSnowGuru/PyTrader-python-mt4-mt5-trading-api-connector-drag-n-drop/tree/master
https://www.mql5.com/en/market/product/58254?source=External#description

1. We can then create a strategy and use reinforcement learning with my PSAR/Impulse/SMI strategy and optimize the parameters 
and then be able to run the strategy in MT4
   - This opens up the door to Renko bars again
   - allows me to stay in python and be able to control the backtesting rather than depending on the MT4 strategy tester


1. Check the integrity of the tickdata - DONE
      - the data looks fairly solid, there were a few instances of the tick data missing a few minutes, but it was a low 
      percentage and pretty consistent across the entire dataset, so nothing to really be concerned about
2. See what impact it will have to not enter a position when the bar closes in the opposite direction


[2024-03-23]
Notes:
Ideas:
# Reinforcement Learning
- I should create a reinforcement learning model that will decide based upon the Double SMA, bollinger bands and Awesome Oscillator (I can change these later)
whether it is a good time to buy, sell, or hold. If the signal is given to buy/sell with a current order, that order will close, and then if the signal appears
again with the next bar then the order will be opened.
- I do this with the parameters that I have found successful so far which is 8.1 brick size, 3 for both sma and smoothing sma
- after that I can take the models as inputs into the GA and optimize the model parameters with GA with the score being how well the model performs
# Double SMA optimization
- Determine if pyramiding trades works better than just taking one trade at a time
    - I believe that I can do this by finding out how many bars are in between the trades and if they are in the same direction, then creating a new order;
    however, I need to look at some of the losing trades and see why they lost
- a pyramid order should be defined as (brick_size * sma_length)
- I am going to assume that the pyramid order will be placed at the close of the bar by using the current spread information provided
[c++]
    double spread;
    SymbolInfoDouble(Symbol(), SYMBOL_SPREAD, spread);
    Print("Current Spread: ", spread);
[end]

TODO:
[√] investigate losing trades
[√] test pyramiding orders
[√] incorporate spread into closing price for pyramiding_orders

Activity Log:

[2024-04-08]
Notes:
Ideas:

TODO:
[ ] Hyperparameter Tuning: Carefully tune the hyperparameters of your PPO algorithm, such as the learning rate, discount factor, and entropy coefficient, to find the optimal configuration for your trading environment.
[ ] Splitting the Data Appropriately: Instead of an 80/20 split, consider using a more rigorous approach, such as a rolling window or a walk-forward validation technique. This will ensure that your testing data is truly independent and representative of the market conditions your model will face in production.
Activity Log:

[2024-04-09]
Notes:
From phind:
[python]
hyperparameters = {
    'lr': [1e-3, 1e-4, 1e-5], # Learning rate
    'gamma': [0.9, 0.95, 0.99], # Discount factor
    'ent_coef': [0.01, 0.05, 0.1] # Entropy coefficient
}
def train_and_evaluate(lr, gamma, ent_coef):
    model_ppo = PPO(policy_ppo, env_train, verbose=0, lr=lr, gamma=gamma, ent_coef=ent_coef)
    model_ppo.learn(total_timesteps=total_learning_timesteps_ppo, callback=ProgressBarCallback(100))
    # Evaluate the model and return the performance metric
    # For example, you might calculate the average reward over a test set
    # This is a placeholder for your evaluation logic
    return average_reward
best_hyperparameters = None
best_performance = -np.inf

for lr in hyperparameters['lr']:
    for gamma in hyperparameters['gamma']:
        for ent_coef in hyperparameters['ent_coef']:
            performance = train_and_evaluate(lr, gamma, ent_coef)
            if performance > best_performance:
                best_performance = performance
                best_hyperparameters = (lr, gamma, ent_coef)

print(f"Best hyperparameters: {best_hyperparameters}")

best_lr, best_gamma, best_ent_coef = best_hyperparameters
model_ppo = PPO(policy_ppo, env_train, verbose=0, lr=best_lr, gamma=best_gamma, ent_coef=best_ent_coef)
model_ppo.learn(total_timesteps=total_learning_timesteps_ppo, callback=ProgressBarCallback(100))

# Walk forward validation: 
env_train = MyForexEnv(
    df=FOREX_EURUSD_RENKO[:split],
    window_size=10,
    frame_bound=(10, split),
    trade_fee=0.0001,
    spread=0.0001,
    spread_bool=False,
    unit_side='right',
    sma_length=4,
    smoothing_sma=4
)

env_test = MyForexEnv(
    df=FOREX_EURUSD_RENKO[split:],
    window_size=10,
    frame_bound=(split, len(FOREX_EURUSD_RENKO)),
    trade_fee=0.0001,
    spread=0.0001,
    spread_bool=False,
    unit_side='right',
    sma_length=4,
    smoothing_sma=4
)

# Set the random seed
seed_ppo = 42
torch.manual_seed(seed_ppo)
random.seed(seed_ppo)
np.random.seed(seed_ppo)

# Initialize the PPO model
model_ppo = PPO(policy_ppo, env_train, verbose=0)

# Iterate through the training and testing sets
for i in range(0, len(FOREX_EURUSD_RENKO) - split, 10):
    # Update the training and testing environments
    env_train.frame_bound = (10, split + i)
    env_test.frame_bound = (split + i, len(FOREX_EURUSD_RENKO))

    # Train the model
    model_ppo.learn(total_timesteps=total_learning_timesteps_ppo // 10)

    # Evaluate the model on the testing set
    obs_test, info_test = env_test.reset()
    done_test = False
    total_reward_test = 0
    while not done_test:
        action_test, _ = model_ppo.predict(obs_test)
        obs_test, reward_test, done_test, info_test = env_test.step(action_test)
        total_reward_test += reward_test

    print(f"Iteration {i}: Testing Reward = {total_reward_test}")

# Save the model after training
model_ppo.save("ppo_model.pkl")

# Load the saved model
model_ppo = PPO.load("ppo_model.pkl", env=env_train)

[end]

Ideas:
TODO:
[ ] continue working with Perplexity to implement Hyperparameter Tuning

Activity Log:
- I created the news events for the entire time of the data, before it only went back to 2022-01-01
   

[2024-04-10]
Notes:
Ideas:
TODO:
[ ] figure out how to change the frame_bound
[ ] figure out what .reset is doing for the environment
Activity Log:


[2024-04-19]
Notes:
Ideas:
TODO:
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
Activity Log:
- I figured out how to connect with MT4 to python and run a script! :) 
- currently training the model to find the best hyperparameters

[2024-04-20]
Notes:
- I need to make a hard cut off for the transition from my personal project and work. 
    - 9:45 am is the cut off time for my personal project
    - 9:45 am - 10:00 am is the time for me to transition to work, wrapping up, putting in my commit messages, 
        and prepping for what I need to do in the next session
    - 10-11 am are meetings
    - 11-11:15 am proritize the tasks from Q-C
    - 11:15-5 pm working for CVS
    - 5-6:30 - working for Q-C

Answers to some of the questions below:
- What are the things to consider when taking a model into production?: 
Model Performance: Ensure your model performs well on unseen data and maintains its performance over time. Regularly evaluate your model's performance using appropriate metrics.

Data Pipeline: Your model's performance depends on the quality of data it receives. Ensure your production data pipeline is robust, reliable, and can handle the scale of data your model needs.

Model Versioning: Keep track of different versions of your model and the data they were trained on. This helps in debugging and allows for rollbacks if necessary

Scalability: Your model should be able to handle increasing amounts of data and requests as your user base grows.

Monitoring: Implement monitoring to track your model's performance and health over time. This helps in identifying and addressing issues promptly.

Security and Privacy: Ensure your model complies with all relevant data privacy laws and regulations. Implement necessary security measures to protect your model and data.

Maintenance: Models may need to be retrained over time as data and requirements change. Plan for regular model updates and maintenance.

Infrastructure: Consider the infrastructure needed to support your model in production. This includes server capacity, storage, and networking capabilities.

Integration: Ensure your model can be integrated smoothly with other parts of your system.

Testing: Implement thorough testing to catch and fix any issues before your model goes live. This includes unit tests, integration tests, and end-to-end tests.

Documentation: Document your model, its inputs and outputs, how it should be used, and any known issues or limitations. This is crucial for effective use and maintenance of your model in production.

What are things that most people don't consider when taking a reinforcement learning model into production:
Non-Stationarity: Unlike supervised learning models, RL models interact with an environment that can change over time. This non-stationarity can lead to model degradation if not properly managed.

Exploration vs Exploitation: RL models need to balance exploration (trying new actions to improve) and exploitation (using known information to make the best decision). This balance can be challenging to maintain in a production environment.

Safety: RL models can make harmful decisions during exploration. It's important to implement safety measures to prevent these actions, especially in sensitive environments.

Reward Engineering: Designing a good reward function can be difficult but it's crucial for RL models. A poorly designed reward function can lead to unintended behavior.

Sample Efficiency: RL models often require a lot of data (experiences) to learn effectively. In a production environment, collecting this data can be time-consuming and costly.

Model Interpretability: RL models can be hard to interpret. This can make it difficult to understand why the model is making certain decisions, which is problematic in many production environments.

Real-time Learning: Many RL applications require the model to learn and make decisions in real time. This can be challenging from a computational perspective.

Evaluation: Evaluating RL models can be tricky as performance can be highly variable and dependent on the initial conditions of the environment.

Reproducibility: RL models can be hard to reproduce due to their interaction with the environment and the stochastic nature of many RL algorithms.

Continuous Deployment: Unlike other models, RL models often need to be continuously updated and deployed as they learn from new data. This requires a robust infrastructure that can support continuous deployment and monitoring.
Ideas:
Questions to answer:
- How often do I need to update the hyperparameters?
- will the model be able to retrain in between receiving new data?
- How well does the model perform on a new week of data?
- What are the things to consider when taking a model into production? -Above-
- What are things that most people don't consider when taking a reinforcement learning model into production?-Above-
- How much data do I need to train on? 
- How do I implement combining this model with my current account protection strategies?
TODO:
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
[ ] create the logic to implement the model in production while the model is still training and finding the hyperparameters
[ ] combine this model with my current account protection strategies?
      - current account protection safeguards:
            1. controlling lot size
                a. trades in runway
                   - I did this by finding the average lot size, multiplying it by 2 for the max lot size
                   - then I looked at both the daily drawdown max and the total drawdown max compared to where I currently stand in drawdown. Then whichever is the least, I divided that number by the number of trades I wanted in the runway. 
                   - then I found the minimum of that and the max lot size to determine the proposed lot size 
                
            2. start and end hours
            3. max_daily_drawdown percent - Done - 
            4. max total drawdown - Done - 
            5. payout max - Done - 
            6. news events
            7. long orders closed at 4-55 pm to protect against swap, shorts kept open - Done - 
            8. closing any order on Friday at 4 pm  - Done - 
            9. 
Activity Log:
- answered questions that I have outstanding
- created the logic to be able to next test weekly hyperparameter updates

[2024-04-21]
Notes:
 I figured out that a learning rate > 0.05 always results in failures, and there is a negative exponential curve that seems to fit the distribution of successes to failures when comparing entropy to learning rate
Ideas:
TODO:
[ ] investigate the hyperparameters and find the best ones
    [ ] determine which hyperparameters were causing the failures
       [√] learning rate upper limit is 0.05
       [√] entropy upper limit is 0.1
          [ ] need to see what the actual results were for these
       [ ] window size
    [ ] figure out the best ones
[ ] logic to implement the model
[ ] combine with current account protection strategies
      [ ] controlling lot size
          [ ] trades in runway
      [ ] start and end hours
      [ ] news events
[ ] Answer the question: did the hyperparameter tuning make a difference for each week of retraining?

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
      
Activity Log:
1. worked on weekly budget for the family
2. looked at hyperparameter distribution of failures

[2024-04-22]
Notes:
 - It might not necessarily be that those hyperparameters didn't work, but that the model never learned completely
    so then when testing the hyperparameters, we get a faulty reading on whether those hyperparameters are good or not
    which would cause issues for the minimization problem
 - so do I need to train the model, test how it does on the training env, then run it in the test environment to evaluate
    the validity of the hyperparameters? - I can have it rerun the training 5 times to see if the model is successful, otherwise
    just say that those hyperparameters failed
Ideas:
TODO:
[ ] investigate the hyperparameters and find the best ones
    [√] determine which hyperparameters were causing the failures
       [√] learning rate upper limit is 0.05
       [√] entropy upper limit is 0.1
          [√] need to see what the actual results were for these
       [√] window size - anything above 10 fails
    [ ] gamma test
    [ ] figure out the best hyperparameters to use (ask GenAI the best way to do this)
[ ] logic to implement the model
[ ] combine with current account protection strategies
      [ ] controlling lot size
          [ ] trades in runway
      [ ] start and end hours
      [ ] news events
[ ] Answer the question: did the hyperparameter tuning make a difference for each week of retraining?

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT

Activity Log:

1. Window size always fails if it is not 10
2. Tested out whether I could weed out the models that didn't train, but this just left all of them failing to train, 
even my best performing model - not sure whether this is important to do
3. started testing whether I need to search for the best hyperparameters every week


[2024-04-23]
Notes:
Ideas:
TODO:
[ ] investigate the hyperparameters and find the best ones
    [√] determine which hyperparameters were causing the failures
       [√] learning rate upper limit is 0.05
       [√] entropy upper limit is 0.1
          [√] need to see what the actual results were for these
       [√] window size - anything above 10 fails
    [ ] gamma test
    [√] figure out the best hyperparameters to use (ask GenAI the best way to do this)
    [ ] Need to test the best model on the testing week
[ ] logic to implement the model
[√] combine with current account protection strategies
      [√] controlling lot size
          [√] trades in runway
      [√] start and end hours
      [√] news events
[ ] Answer the question: did the hyperparameter tuning make a difference for each week of retraining? YES

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT

Activity Log:
1. I added all of the account protection strategies to the function that will implement the model
2. I started investigating whether I need to do the hyperparameter search every week
3. The answer is Yes, it makes a significant difference and I will need to continue to search for the best hyperparameters each week.
3. Answer to the question of: How do I figure out the best hyperparameters to use?
    Determining the best hyperparameters for a model that generalizes well across different data and time periods, especially for deployment in production, involves a combination of strategies. Here are some approaches to consider:

    ### 1. **Cross-Validation**

    Use cross-validation to estimate the performance of your model with different hyperparameters. Cross-validation involves splitting your dataset into multiple subsets and training your model on some of these subsets while validating it on others. This process helps ensure that your model's performance is not overly optimistic due to overfitting to a single training set.

    - **Time Series Cross-Validation**: For time series data, you can use time series cross-validation, which involves creating multiple training and validation sets by splitting the data at different points in time. This ensures that your model is evaluated on data that it has not seen during training, providing a more realistic estimate of its performance.

    ### 2. **Hyperparameter Optimization with Robustness Testing**

    When optimizing hyperparameters, consider not only the performance on your current dataset but also how well the model generalizes to new data. This can be done by:

    - **Holdout Validation Set**: Keep a separate validation set that is not used during the hyperparameter optimization process. This set should be representative of the data the model will encounter in production. Evaluate the performance of the model with the best hyperparameters on this validation set.

    - **Incremental Validation**: As you update your model with new data, periodically re-evaluate the model's performance with the best hyperparameters on the new data. This helps ensure that the model remains robust as new data comes in.

    ### 3. **Monitoring and Adaptation**

    - **Monitoring in Production**: Once your model is deployed, continuously monitor its performance in production. Use this data to adjust hyperparameters as needed.

    - **Adaptive Hyperparameter Tuning**: Implement a system that can adapt the model's hyperparameters based on its performance in production. This could involve re-running hyperparameter optimization with the new data or using more sophisticated techniques like online learning or adaptive hyperparameter tuning algorithms.

    ### 4. **Domain Knowledge and Feature Engineering**

    - **Domain Knowledge**: Use your understanding of the problem domain to guide the selection of hyperparameters. For example, if you know that certain features are more important than others, you might choose hyperparameters that emphasize these features.

    - **Feature Engineering**: Experiment with different feature engineering techniques to see if they improve the model's performance. This could involve creating new features, selecting different subsets of existing features, or transforming features in different ways.

    ### 5. **Regular Experimentation and Evaluation**

    - **Experimentation**: Regularly experiment with different hyperparameters, feature engineering techniques, and model architectures. Use cross-validation and holdout validation to estimate the performance of these changes.

    - **Evaluation**: Evaluate the performance of your model not just on accuracy or other traditional metrics, but also on its ability to generalize to new data and its robustness to changes in the data.

    ### 6. **Ensemble Methods**

    - **Ensemble Methods**: Consider using ensemble methods, which combine the predictions of multiple models trained with different hyperparameters or data subsets. This can help improve the model's robustness and generalization.

    By combining these strategies, you can develop a model that not only performs well on your current dataset but also remains robust and effective as new data comes in and as the underlying data distribution changes.


[2024-04-24]
Notes:
Ideas:
TODO:
[ ] investigate the hyperparameters and find the best ones
    [√] determine which hyperparameters were causing the failures
       [√] learning rate upper limit is 0.05
       [√] entropy upper limit is 0.1
          [√] need to see what the actual results were for these
       [√] window size - anything above 10 fails
    [ ] gamma test
    [ ] Need to test the best model on the testing week
    [√] look into how reward is calculated and if my account protection strategies can safeguard me from a model that has a bad run
[ ] logic to implement the model
[ ] test the code with a basic model that might not be the best

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
1. Volume is calculated as an output from the model, so I can easily protect against this with forcing the orders to be my volume, not the model's volume

[2024-04-25]
Notes:
Ideas:
1. I can just create an observation without the environment, so I create the observation from the data, provide it to the model, the model gives a prediction, and produces an action. I can then take that action, and use it to perform a step and use the parameters received within the action to then place/hold/close the order. then after the fact I can update the environment and have it reset with the next observation and data added. And re-train the model if need be.
TODO:
[ ] investigate the hyperparameters and find the best ones
    [√] determine which hyperparameters were causing the failures
       [√] learning rate upper limit is 0.05
       [√] entropy upper limit is 0.1
          [√] need to see what the actual results were for these
       [√] window size - anything above 10 fails
    [ ] gamma test
    [ ] Need to test the best model on the testing week
    [√] look into how reward is calculated and if my account protection strategies can safeguard me from a model that has a bad run
[ ] logic to implement the model
[ ] test the code with a basic model that might not be the best

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
1. Started looking into the actual implementation of the model and how to get it to interact with the environment. 
2. Set up the environment, and importing the model. 
3. Trying to determine the best setup for the model without it taking a ridiculously long time for the model to make a decision by providing it with an observation which I can grab from MetaTrader.


[2024-04-26]
Notes:
The *Gym observation_space* property. Each observation contains information about *balance*, *equity*, *margin*, *features*, and *orders*. The **features** is a window on the *signal_features* from index *current_tick - window_size + 1* to *current_tick*. The **orders** is a 3D array. Its first dimension specifies the symbol index in the *trading_symbols* list. The second dimension specifies the order number (each symbol can have more than one open order at the same time in hedge trading). The last dimension has three elements, *entry_price*, *volume*, and *profit* of corresponding order.
Ideas:
TODO:
[ ] investigate the hyperparameters and find the best ones
    [√] determine which hyperparameters were causing the failures
       [√] learning rate upper limit is 0.05
       [√] entropy upper limit is 0.1
          [√] need to see what the actual results were for these
       [√] window size - anything above 10 fails
    [ ] gamma test
        [ ] need to see the distribution of gamma and whether I need to continue to add this into the hyperparameters or not
    [ ] Need to test the best model on the testing week
    [ ] create a function that will calculate the profit factor for the model as the "loss" that will go into the hyperparameter search. Using my way of calculating the profit and including the stoploss 
[ ] logic to implement the model
    [ ] create the observation from the data
        I need to provide:
        [ ] balance - account info
        [ ] equity  - account info
        [ ] margin  - account info
        [ ] features- 10 rows of close, open prices from the last 10 bars
        [ ] orders
    [ ] provide the observation to the model
    [ ] model gives a prediction
    [ ] produce an action
    [ ] take that action
    [ ] use the parameters received within the action to then place/hold/close the order
    [ ] update the environment
    [ ] reset with the next observation and data added
    [ ] re-train the model if need be
[ ] test the code with a basic model that might not be the best

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
1. looked into the results of the hyperparameter test, and I am unsure of whether to keep gamma in the hyperparameters or not
       - I need to see how well these perform on the testing week - then choose my hyperparameters from there.
2. Looked into the Profit calculated by the model during a test week. 
3. Figured out how to create an observation for the model to predict from
4. created a function that will calculate the profit factor for the model as the "loss" that will go into the 
hyperparameter search. Using my way of calculating the profit and including the stoploss 

[2024-04-27]
Notes:
Ideas:
TODO:
[√] investigate the hyperparameters and find the best ones
    [√] determine which hyperparameters were causing the failures
       [√] learning rate upper limit is 0.05
       [√] entropy upper limit is 0.1
          [√] need to see what the actual results were for these
       [√] window size - anything above 10 fails
    [√] gamma test
        [√] need to see the distribution of gamma and whether I need to continue to add this into the hyperparameters or not
    [√] Need to test the best model on the testing week
    [√] create a function that will calculate the profit factor for the model as the "loss" that will go into the hyperparameter search. Using my way of calculating the profit and including the stoploss 
    [√] figure out if I should train with more timesteps on the model with the best hyperparameters or keep it at 50
[ ] logic to implement the model
    [ ] create the observation from the data
        I need to provide:
        [ ] balance - account info
        [ ] equity  - account info
        [ ] margin  - account info
        [ ] features- 10 rows of close, open prices from the last 10 bars
        [ ] orders - dynamic account info
    [ ] provide the observation to the model
    [ ] model gives a prediction
    [ ] produce an action
    [ ] take that action
    [ ] use the parameters received within the action to then place/hold/close the order
    [ ] update the environment
    [ ] reset with the next observation and data added
    [ ] re-train the model if need be - this poses a risk since the model might not successfully train each time
[ ] test the code with a basic model that might not be the best

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
I think gamma hyperparameter should stay. 

Tested the top performing hyperparameters and they all looked good. the ones that didn't perform as well during the hyperparameter search, also didn't do as well and there was a higher occurrence of them actually producing losses on average but the top 5 all looked good. There were a few outliers, like the best model was somewhere at the top of the other, but I think we should be good taking the top performer each week. 

implemented the work that I needed to save the model and have it ready for production.

Created a new notebook that I will use to save the model and send it to production

Checked the data in a single observation, and it is definitely something I can provide the model


[2024-04-28]
Notes:
Ideas:
- If I go and get all of the data from using the pytrader connector, then train the model on all of that, then run several simulations with the last week of the data and then use that model as the one for the test run, does it perform better? [optimization]
- Need to determine how to best update the simulator with a new datapoint
    - I'm thinking that I grab the new data from the broker, then I concat that with the current dataframe that was in the pickle file, then I re-save the pickle file with the new data appended and then reload the data on the simulator

TODO:
[ ] logic to implement the model
    [ ] create the observation from the data
        I need to provide:
        [ ] balance - account info
        [ ] equity  - account info
        [ ] margin  - account info
        [ ] features- 10 rows of close, open prices from the last 10 bars
        [ ] orders - dynamic account info
    [ ] provide the observation to the model
    [ ] model gives a prediction
    [ ] produce an action
    [ ] take that action
    [ ] use the parameters received within the action to then place/hold/close the order
    [ ] update the environment
    [ ] reset with the next observation and data added
    [ ] re-train the model if need be - this poses a risk since the model might not successfully train each time
[ ] test the code with a basic model that might not be the best

[ ]  look at the distribution for the finished hyperparameter searches
Activity Log:



[2024-04-29]
Notes:
Ideas:
- Does it perform better on a blank environment, or one with a week's worth of orders already placed in? 
    - does it matter whether those orders are profitable or not?
TODO:
[ ] logic to implement the model
    [ ] initialize the production_environment with a week's worth of data (maybe?)
    [ ] update the datapoints
    [ ] allow the environment to tell me whether to hold, open or close an order
[ ] test the code with a basic model that might not be the best
[ ] figure out how to best deal with volume issue

[ ]  look at the distribution for the finished hyperparameter searches

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

1. found out that I don't need to do any of that. I can just update the environment with each new datapoint and then get the environment to read the observation for me, and return whether or not I should place an order

[2024-04-30]
Notes:
Ideas:
TODO:
[ ] logic to implement the model
    [√] initialize the production_environment with a week's worth of data
    [√] update the datapoints
    [√] update the load_env function
    [ ] allow the environment to tell me whether to hold, open or close an order
[ ] test the code with a basic model that might not be the best
[ ] figure out how to best deal with volume issue - does this have an impact on training the model? 

[ ]  look at the distribution for the finished hyperparameter searches

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

added a pickle file for the production which takes the last week


[2024-05-01]
Notes:
Ideas:
TODO:
[√] logic to implement the model
    [√] allow the environment to tell me whether to hold, open or close an order
[ ] test the code with a basic model that might not be the best


[ ] figure out how to best deal with volume issue - does this have an impact on training the model? 

[ ]  look at the distribution for the finished hyperparameter searches

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
Added closing conditions to the RL model
- started testing out the code and going through it line-by-line

[2024-05-02]
Notes:

importlib.reload(fx_rl)

- always make sure that you get the production data and start the script before the next interval starts
Ideas:
TODO:
[√] test the code with a basic model that might not be the best, but I can optimize later

[ ] determine whether the VPS that I am using is what I need, or whether I can get a cheaper one. 


[ ] figure out how to best deal with volume issue - does this have an impact on training the model? 
[ ]  look at the distribution for the finished hyperparameter searches

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
ran through all of the code for RL and checked everything. Everything looks good. Trades opened, I was able to set the stoploss, and the trades closed. Really successful time

trying to get the script to run - it runs!!! SWEET !!!

Have to get the prices before we process the data! DUH!


[2024-05-03]
Notes:
Current VPS:
($123)
Premium Beta VPS (LD4)
- Location: Equinix LD4 Data Center, UK
- 3.5-3.7 GHz CPU clock frequency
- 4 VCPU Core
- 6 GB RAM
- 40 GB SSD
- 10Gb/sec ultra low latency ASIC network card
Possible VPS' that I can use:
- Kamatera - 8 GB RAM, 50GB SSD = $41/mo

- there was a bug that happened where I lost the ID of an order, and it wasn't in the dictionary
Ideas:
TODO:
[√] fix bug where the entry price is exactly the same every hour even though the price is changing

[√] determine whether the VPS that I am using is what I need, or whether I can get a cheaper one. 

[ ] figure out how to best deal with volume issue - does this have an impact on training the model? 
[ ]  look at the distribution for the finished hyperparameter searches

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
fixed bug where the entry price was the same every hour
fixed several other bugs that arose from that issue

[2024-05-04]
Notes:
Ideas:
TODO:
[√] analyze the results from the test run yesterday
[ ] figure out how to best deal with volume issue - does this have an impact on training the model? 
[√] look at the distribution for the finished hyperparameter searches

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

- analyzed the results from the test run yesterday, everything is looking good, all I did was add a safeguard for the first 2 runs of getting new data, I made it so that those first 2 orders would be 0.01, because they were significantly off in the results for the entry and exit prices

- investigated the distribution of the hyperparameter searches. Found new upper bounds for the distributions

- the profit factor worked out really well. Didn't see those huge losses like before

[2024-05-05]
Notes:
- the hyperparameter search needs to be done with the validation week being the week that just ended.
- this week ended with May 3rd, the training should be evertyhing before April 26th, and then the validation should be for the week ending in the 3rd.
Ideas:
TODO:
[ ] prepare for next stage of testing that will start Sunday -> Tuesday Morning
[ ] Use the same model from Friday -> the main test will be whether we can get it working on the VPS and how it does up there.
[ ] during that time Monday morning -> analyze the results from the hyperparameter searches comparing the volumes, then we need to 
         run the hyperparameter search with either the old volume calc or the new, and then use the best hyperparameters from that search that will run on Monday, to then generate a model that we can run 
         starting on Tuesday morning
      [ ] get the model ready
          [ ] getting the correct parameters
          [ ] putting that into Saving_tested_model notebook running it on 250K learning timesteps
          [ ] saving the model into its location on the init__.py file
          [ ] restarting the script on the VPS
      

[ ] figure out how to best deal with volume issue - does this have an impact on training the model? 
[ ] compare the hyperparameter searches for the new and old volume calculations

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:


[2024-05-06]
Notes:
Ideas:
TODO:
[√] prepare for next stage of testing that will start Sunday -> Tuesday Morning
[√] Use the same model from Friday -> the main test will be whether we can get it working on the VPS and how it does up there.
[ ] during that time Monday morning -> analyze the results from the hyperparameter searches comparing the volumes, then we need to 
         run the hyperparameter search with either the old volume calc or the new, and then use the best hyperparameters from that search that will run on Monday, to then generate a model that we can run 
         starting on Tuesday morning
      [√] get the model ready
          [√] getting the correct parameters
          [√] putting that into Saving_tested_model notebook running it on 250K learning timesteps
          [√] saving the model into its location on the init__.py file
          [√] restarting the script on the VPS
      

[ ] figure out how to best deal with volume issue - does this have an impact on training the model? 
    [ ] compare the hyperparameter searches for the new and old volume calculations

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

Got the model working on the VPS

[2024-05-07]
Notes:
keep the new way of calculating volume
Ideas:
TODO:
[ ] figure out if I have the right calculation for estimating spread

[√] during that time Monday morning -> analyze the results from the hyperparameter searches comparing the volumes, then we need to 
         [√] run the hyperparameter search with either the old volume calc or the new, and then use the best hyperparameters from that search that will run on Monday, to then generate a model that we can run 
         [√] starting on Tuesday morning      

[√] figure out how to best deal with volume issue - does this have an impact on training the model? 
    [√] compare the hyperparameter searches for the new and old volume calculations

[ ] figure out how this works on different timeframes through the simulation
    [ ] test training it on the 1hr timeframe, then test on 5 min timeframe
    [ ] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

started trying to compare the old and new volume calculations, and there isn't a significant difference between the 2

[2024-05-08]
Notes:
Ideas:
TODO:
[√] figure out if I have the right formula for estimating spread

[ ] figure out how this works on different timeframes through the simulation
    [√] test training it on the 1hr timeframe, then test on 5 min timeframe
    [ ] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe

[ ] determine the best size for the model to train on

[ ] test whether the model performs better when re-training with every additional timestep

[ ] add more data for the model to work with
   [ ] OHLCV instead of just OC 
   [ ] add the time until the next news event
   [ ] add some indicators

[ ] find more hyperparameters to tune that might impact the ability of the model to be more successful

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

I believe I do have a good formula for estimating spread. But will need to check this at the end of the week when I'm analyzing everything else

not a good idea to train and run on different timeframes.

[2024-05-09]
Notes:
Ideas:
TODO:
[ ] figure out how this works on different timeframes through the simulation
    [ ] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe

[ ] determine the best size dataset for the model to train on

[ ] test whether the model performs better when re-training with every additional timestep

[ ] add more data for the model to work with
   [ ] OHLCV instead of just OC 
   [ ] add the time until the next news event
   [ ] add some indicators

[ ] find more hyperparameters to tune that might impact the ability of the model to be more successful

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

[2024-05-10]
Notes:

For the weekend hyperparameter search
- check the number of orders - make sure this is > 10
- 

Ideas:
TODO:
TOP PRIORITY
[ ] update the model to close a trade in the simulator if the stoploss is hit so that it can potentially open a new trade

[√] figure out how this works on different timeframes through the simulation
    [√] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe
    [ ] analyze gym_mtsim_forked/examples/hyperopt/trials_5_8_timeframe_test.pkl

[ ] start running the hyperparameter search for 15 and 5 min timeframes on how many bars I need to train on.

[√] determine the best sized dataset for the model to train on

[ ] test whether the model performs better when re-training with every additional timestep

[ ] add more data for the model to work with
   [ ] OHLCV instead of just OC 
   [ ] add the time until the next news event
   [ ] add some indicators

[ ] find more hyperparameters to tune that might impact the ability of the model to be more successful

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT

Activity Log:

determined that 1 hr was the best timeframe when only training the data on the weekend and then using the same model for the entire week, but if we were to 

[2024-05-11]
Notes:
Ideas:
TODO:
[ ] check whether the new functionality works for closing a trade in the simulator when the stoploss is hit
TOP PRIORITY
[√] update the model to close a trade in the simulator if the stoploss is hit so that it can potentially open a new trade

[√] figure out how this works on different timeframes through the simulation
    [√] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe
    [ ] analyze gym_mtsim_forked/examples/hyperopt/trials_5_8_timeframe_test.pkl

[ ] start running the hyperparameter search for 15 and 5 min timeframes on how many bars I need to train on.

[√] determine the best sized dataset for the model to train on

[ ] test whether the model performs better when re-training with every additional timestep

[ ] add more data for the model to work with
   [ ] OHLCV instead of just OC 
   [ ] add the time until the next news event
   [ ] add some indicators

[ ] find more hyperparameters to tune that might impact the ability of the model to be more successful

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:
- added functionality for closing trades when stoploss is hit

analyzed results from this week, everything looks fine. Just not a profitable week. Had a lot of times where the SL was hit
- training data size inconclusive

[2024-05-12]
Notes:
Ideas:
- is performance on the validation week, always a predictor of performance on the testing week?
    - I might be able to use this to understand if the results that I run on the simulation of the data prior to 
    starting to run the model in the real world is a good validation run or not

- main will be my production code
TODO:
[ ] check whether the new functionality works for closing a trade in the simulator when the stoploss is hit

[√] figure out how this works on different timeframes through the simulation
    [√] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe
    [ ] analyze gym_mtsim_forked/examples/hyperopt/trials_5_8_timeframe_test.pkl

[ ] start running the hyperparameter search for 15 and 5 min timeframes on how many bars I need to train on.

[ ] test whether the model performs better when re-training with every additional timestep

[ ] add more data for the model to work with
   [√] OHLCV instead of just OC 
   [ ] add the time until the next news event
   [ ] add some indicators

[ ] find more hyperparameters to tune that might impact the ability of the model to be more successful

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:


[2024-05-14]
Notes:
Ideas:
TODO:
[ ] check whether the new functionality works for closing a trade in the simulator when the stoploss is hit

[ ] figure out how this works on different timeframes through the simulation
    [ ] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe

[ ] start running the hyperparameter search for 15 and 5 min timeframes on how many bars I need to train on.

[√] test whether the model performs better when re-training each day

[ ] add more data for the model to work with
   [√] OHLCV instead of just OC 
   [ ] add the time until the next news event
   [ ] add some indicators

[ ] find more hyperparameters to tune that might impact the ability of the model to be more successful

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

- logic for retraining the model every day
- found out that this was not a good method to use

[2024-05-15]
Notes:
Ideas:
TODO:
[ ] check whether the new functionality works for closing a trade in the simulator when the stoploss is hit

[ ] figure out how this works on different timeframes through the simulation
    [ ] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe
    [ ] combine increasing_data_for_model and saving_tested_model hyperparameter search logic to test this

[ ] start running the hyperparameter search for 15 and 5 min timeframes on how many bars I need to train on.

[√] test whether the model performs better when re-training each day

[ ] add more data for the model to work with
   [√] OHLCV instead of just OC 
   [ ] add the time until the next news event
   [ ] add some indicators

[ ] find more hyperparameters to tune that might impact the ability of the model to be more successful

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

[2024-05-16]
Notes:
Ideas:
TODO:
[√] create a plan for the other freelance sites to apply to on which day - have the last day be for enhancing Fiverr gigs
[√] create the business loan amoritization schedule
[√] Find a replacement for github copilot


[ ] check whether the new functionality works for closing a trade in the simulator when the stoploss is hit

[ ] figure out how this works on different timeframes through the simulation
    [ ] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe
    [√] combine increasing_data_for_model and saving_tested_model hyperparameter search logic to test this

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

1. applied for proxify.io
2. restarted the gigs on Fiverr - still need to optimize all of these and update with latest info about me
3. Created a plan for applying to other freelance sites over the next week
4. Created the loan amortization schedule for business loan
5. Updated loan amoritization schedule for home improvement loans
6. Combined increasing_data_for_model and saving_tested_model hyperparameter search logic to test the timeframe
7. Found an alternative to github copilot

[2024-05-18]
Notes:
Ideas:
TODO:
[ ] check whether the new functionality works for closing a trade in the simulator when the stoploss is hit

[√] figure out how this works on different timeframes through the simulation
    [√] training it on 5 min timeframe with 100_000 bars, then running on 5 min timeframe
    [√] combine increasing_data_for_model and saving_tested_model hyperparameter search logic to test this
    [√] investigate the hyperparameter results from 5_16_timeframe_analysis...pkl

Long-term
[ ] Start working on AI Agents that will find the most profitable method and test it on the data
[ ] investigate the ability to use TimeGPT
Activity Log:

Longer timeframes are more successful than shorter timeframes

[2024-05-19]
Notes:
Ideas:
TODO:
update VPS
run all the models that I created yesterday and compare whether there is actually any type of significant difference 
when running them 1_000 times throug the validation
Activity Log:


I have a csv file that combines several weeks of my Reinforcement learning trading bot placing orders. It has the time that it was placed, price, number of lots, time that it was closed, closing price, profit of the trade. What would be a great way to go about analyzing this data to glean insights that would allow me to improve the performance of the Reinforcement learning trading bot? 
analyzing the trades made by the bot: 

That's a great question! Analyzing your trading bot's performance data is crucial for improvement. Here's a breakdown of how to analyze your CSV data and gain actionable insights:

**1. Data Preparation & Cleaning:**

* **Import and Format:** Start by importing the CSV file into a suitable environment like Python with Pandas or a spreadsheet software like Excel. Ensure the date and time columns are in the correct format for analysis.
* **Cleaning:** Check for any missing values or inconsistencies in the data. Address these issues by either removing or imputing missing data.

**2. Basic Performance Metrics:**

* **Overall Profitability:** Calculate the total profit/loss across all trades. This gives you a high-level view of the bot's performance.
* **Win Rate:** Determine the percentage of trades that resulted in a profit. This helps understand the bot's consistency in making profitable decisions.
* **Average Profit/Loss:** Calculate the average profit per winning trade and the average loss per losing trade. This reveals the risk-reward profile of the bot's trading strategy.
* **Maximum Drawdown:**  Identify the largest percentage drop in the trading account balance from its peak. This is a crucial measure of risk and helps understand the potential for losses.

**3. Time-Based Analysis:**

* **Profit/Loss over Time:** Plot the cumulative profit/loss over time to visualize the bot's performance trends. Look for periods of sustained profitability or consistent losses.
* **Time of Day Analysis:** Segment trades based on different times of the day. See if the bot performs better during specific trading sessions or market conditions.
* **Holding Period Analysis:** Analyze the average holding period for winning and losing trades. This can reveal if the bot is exiting trades too early or holding onto losing positions for too long.

**4. Price and Volume Analysis:**

* **Entry and Exit Points:** Examine the distribution of entry and exit prices. Are there any price levels that consistently lead to profitable trades? 
* **Price Volatility:** Investigate the relationship between price volatility and trade profitability. Does the bot perform better during periods of high or low volatility?
* **Volume Analysis:**  Analyze the trading volume at entry and exit points. See if the bot performs better in high or low liquidity conditions.

**5. Trade-Specific Analysis:**

* **Profit by Trade Size:** Examine the relationship between the number of lots traded and the profit/loss. Does the bot perform better with larger or smaller positions?
* **Trade Reason:** If your bot logs the reasoning behind each trade (e.g., technical indicators, news events), analyze the profitability of trades based on these reasons.

**6. Advanced Analysis and Machine Learning:**

* **Feature Importance:** If your reinforcement learning model allows it, explore feature importance to understand which factors influence the bot's decision-making. This can guide you in refining the input features for the model.
* **Backtesting:** Use historical data to simulate the bot's trading strategy with different parameters or modifications. This helps evaluate potential improvements before deploying them in live trading.

**Tools and Visualization:**

* **Python Libraries:** Pandas, NumPy, Matplotlib, Seaborn
* **Spreadsheet Software:** Excel, Google Sheets
* **Trading Platforms:** Many platforms offer built-in backtesting and performance analysis tools.

**Key Takeaways for Improving the Bot:**

* **Identify Patterns:** Look for recurring patterns in profitable and losing trades to pinpoint strengths and weaknesses in your bot's strategy.
* **Adjust Parameters:** Based on your analysis, fine-tune the parameters of your reinforcement learning model (e.g., learning rate, reward function) to optimize its decision-making.
* **Feature Engineering:** Consider adding or modifying input features to provide the bot with more relevant information for improved trading decisions.
* **Risk Management:**  Implement appropriate risk management strategies, such as stop-loss orders and position sizing rules, based on the bot's performance and your risk tolerance. 

Remember that thorough analysis and iterative improvement are key to developing a successful reinforcement learning trading bot. 
